{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-SF-34 | Unit Project | 3 | Machine Learning Modeling and Executive Summary | Starter Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you will perform a logistic regression on the admissions data we've been working with in Unit Projects 1 and 2.  You will summarize and present your findings and the methods you used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  prestige\n",
       "0        0  380.0  3.61       3.0\n",
       "1        1  660.0  3.67       3.0\n",
       "2        1  800.0  4.00       1.0\n",
       "3        1  640.0  3.19       4.0\n",
       "4        0  520.0  2.93       4.0\n",
       "..     ...    ...   ...       ...\n",
       "395      0  620.0  4.00       2.0\n",
       "396      0  560.0  3.04       3.0\n",
       "397      0  460.0  2.63       2.0\n",
       "398      0  700.0  3.65       2.0\n",
       "399      0  600.0  3.89       3.0\n",
       "\n",
       "[397 rows x 4 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join('..', '..', 'dataset', 'dataset-ucla-admissions.csv'))\n",
    "df.dropna(inplace = True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A.  Frequency Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 1.  Create a frequency table for `prestige` and whether an applicant was admitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0    148\n",
       "3.0    121\n",
       "4.0     67\n",
       "1.0     61\n",
       "Name: prestige, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "df.prestige.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>admit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prestige</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     admit\n",
       "prestige       \n",
       "1.0          61\n",
       "2.0         148\n",
       "3.0         121\n",
       "4.0          67"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(df.prestige, 'admit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B.  Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 2.  Create a one-hot encoding for `prestige`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1.0  2.0  3.0  4.0\n",
       "0      0    0    1    0\n",
       "1      0    0    1    0\n",
       "2      1    0    0    0\n",
       "3      0    0    0    1\n",
       "4      0    0    0    1\n",
       "..   ...  ...  ...  ...\n",
       "395    0    1    0    0\n",
       "396    0    0    1    0\n",
       "397    0    1    0    0\n",
       "398    0    1    0    0\n",
       "399    0    0    1    0\n",
       "\n",
       "[397 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "presdf = pd.get_dummies(df.prestige)\n",
    "presdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 3.  How many of these binary variables do we need for modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: 3! The model should assume 3 0's means the last variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 4.  Why are we doing this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: To be able to model the classification variable, prestige"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 5.  Add all these binary variables in the dataset and remove the now redundant `prestige` feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>prestige</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  prestige  1.0  2.0  3.0  4.0\n",
       "0        0  380.0  3.61       3.0    0    0    1    0\n",
       "1        1  660.0  3.67       3.0    0    0    1    0\n",
       "2        1  800.0  4.00       1.0    1    0    0    0\n",
       "3        1  640.0  3.19       4.0    0    0    0    1\n",
       "4        0  520.0  2.93       4.0    0    0    0    1\n",
       "..     ...    ...   ...       ...  ...  ...  ...  ...\n",
       "395      0  620.0  4.00       2.0    0    1    0    0\n",
       "396      0  560.0  3.04       3.0    0    0    1    0\n",
       "397      0  460.0  2.63       2.0    0    1    0    0\n",
       "398      0  700.0  3.65       2.0    0    1    0    0\n",
       "399      0  600.0  3.89       3.0    0    0    1    0\n",
       "\n",
       "[397 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "df = df.join([presdf])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  1.0  2.0  3.0  4.0\n",
       "0        0  380.0  3.61    0    0    1    0\n",
       "1        1  660.0  3.67    0    0    1    0\n",
       "2        1  800.0  4.00    1    0    0    0\n",
       "3        1  640.0  3.19    0    0    0    1\n",
       "4        0  520.0  2.93    0    0    0    1\n",
       "..     ...    ...   ...  ...  ...  ...  ...\n",
       "395      0  620.0  4.00    0    1    0    0\n",
       "396      0  560.0  3.04    0    0    1    0\n",
       "397      0  460.0  2.63    0    1    0    0\n",
       "398      0  700.0  3.65    0    1    0    0\n",
       "399      0  600.0  3.89    0    0    1    0\n",
       "\n",
       "[397 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('prestige', axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = ['admit', 'gre', 'gpa', 'one', 'two', 'three', 'four']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>0</td>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     admit    gre   gpa  one  two  three  four\n",
       "0        0  380.0  3.61    0    0      1     0\n",
       "1        1  660.0  3.67    0    0      1     0\n",
       "2        1  800.0  4.00    1    0      0     0\n",
       "3        1  640.0  3.19    0    0      0     1\n",
       "4        0  520.0  2.93    0    0      0     1\n",
       "..     ...    ...   ...  ...  ...    ...   ...\n",
       "395      0  620.0  4.00    0    1      0     0\n",
       "396      0  560.0  3.04    0    0      1     0\n",
       "397      0  460.0  2.63    0    1      0     0\n",
       "398      0  700.0  3.65    0    1      0     0\n",
       "399      0  600.0  3.89    0    0      1     0\n",
       "\n",
       "[397 rows x 7 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C.  Hand calculating odds ratios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's develop our intuition about expected outcomes by hand calculating odds ratios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 6.  Create a frequency table for `prestige = 1` and whether an applicant was admitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>admit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  admit\n",
       "one         \n",
       "0        336\n",
       "1         61"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "pd.crosstab(df.one, 'admit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 7.  Use the frequency table above to calculate the odds of being admitted to graduate school for applicants that attended the most prestigious undergraduate schools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.153652392947\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "p = 61. / (336 + 61) \n",
    "print p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18154761904761907"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = p /(1 - p)\n",
    "pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 8.  Now calculate the odds of admission for undergraduates who did not attend a #1 ranked college."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8463476070528967"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "q = 336. / (397)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.5081967213114735"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qq = q / (1 - q)\n",
    "qq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 9.  Finally, what's the odds ratio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.032959537981859424"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "pp / qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 10.  Write this finding in a sentence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: The odds of admission when from a prestige 1 school is significantly lower than from other schools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 11.  Use the frequency table above to calculate the odds of being admitted to graduate school for applicants that attended the least prestigious undergraduate schools.  Then calculate their odds ratio of being admitted to UCLA.  Finally, write this finding in a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>admit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0  admit\n",
       "four        \n",
       "0        330\n",
       "1         67"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "pd.crosstab(df.four, 'admit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04122130394857666"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = 67. / (330 + 67)\n",
    "q = 330. / (397)\n",
    "pp = p / (1-p)\n",
    "qq = q / (1-q)\n",
    "pp / qq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Being from a prestige 4 lowers your chances of entry into UCLA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D. Analysis using `statsmodels`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 12.  Fit a logistic regression model predicting admission into UCLA using `gre`, `gpa`, and the `prestige` of the undergraduate schools.  Use the highest prestige undergraduate schools as your reference point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      1\n",
      "2      1\n",
      "3      1\n",
      "4      0\n",
      "      ..\n",
      "395    0\n",
      "396    0\n",
      "397    0\n",
      "398    0\n",
      "399    0\n",
      "Name: admit, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>two</th>\n",
       "      <th>three</th>\n",
       "      <th>four</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>380.0</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>660.0</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>800.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>640.0</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>520.0</td>\n",
       "      <td>2.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>620.0</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>560.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>460.0</td>\n",
       "      <td>2.63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>700.0</td>\n",
       "      <td>3.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>600.0</td>\n",
       "      <td>3.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>397 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gre   gpa  two  three  four\n",
       "0    380.0  3.61    0      1     0\n",
       "1    660.0  3.67    0      1     0\n",
       "2    800.0  4.00    0      0     0\n",
       "3    640.0  3.19    0      0     1\n",
       "4    520.0  2.93    0      0     1\n",
       "..     ...   ...  ...    ...   ...\n",
       "395  620.0  4.00    1      0     0\n",
       "396  560.0  3.04    0      1     0\n",
       "397  460.0  2.63    1      0     0\n",
       "398  700.0  3.65    1      0     0\n",
       "399  600.0  3.89    0      1     0\n",
       "\n",
       "[397 rows x 5 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "admit = df.admit\n",
    "X = df[['gre', 'gpa', 'two', 'three', 'four']]\n",
    "print admit\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.589121\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x11097ad50>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.Logit(admit, X).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 13.  Print the model's summary results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.589121\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>admit</td>      <th>  No. Observations:  </th>  <td>   397</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   392</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     4</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 11 Jun 2017</td> <th>  Pseudo R-squ.:     </th>  <td>0.05722</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>09:58:59</td>     <th>  Log-Likelihood:    </th> <td> -233.88</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -248.08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.039e-05</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>   <td>    0.0014</td> <td>    0.001</td> <td>    1.308</td> <td> 0.191</td> <td>   -0.001     0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>   <td>   -0.1323</td> <td>    0.195</td> <td>   -0.680</td> <td> 0.497</td> <td>   -0.514     0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>two</th>   <td>   -0.9562</td> <td>    0.302</td> <td>   -3.171</td> <td> 0.002</td> <td>   -1.547    -0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>three</th> <td>   -1.5375</td> <td>    0.332</td> <td>   -4.627</td> <td> 0.000</td> <td>   -2.189    -0.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>four</th>  <td>   -1.8699</td> <td>    0.401</td> <td>   -4.658</td> <td> 0.000</td> <td>   -2.657    -1.083</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  397\n",
       "Model:                          Logit   Df Residuals:                      392\n",
       "Method:                           MLE   Df Model:                            4\n",
       "Date:                Sun, 11 Jun 2017   Pseudo R-squ.:                 0.05722\n",
       "Time:                        09:58:59   Log-Likelihood:                -233.88\n",
       "converged:                       True   LL-Null:                       -248.08\n",
       "                                        LLR p-value:                 1.039e-05\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "gre            0.0014      0.001      1.308      0.191        -0.001     0.003\n",
       "gpa           -0.1323      0.195     -0.680      0.497        -0.514     0.249\n",
       "two           -0.9562      0.302     -3.171      0.002        -1.547    -0.365\n",
       "three         -1.5375      0.332     -4.627      0.000        -2.189    -0.886\n",
       "four          -1.8699      0.401     -4.658      0.000        -2.657    -1.083\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "smf.Logit(admit, X).fit().summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573854\n",
      "         Iterations 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterr/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>admit</td>      <th>  No. Observations:  </th>  <td>   397</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   391</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     5</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 11 Jun 2017</td> <th>  Pseudo R-squ.:     </th>  <td>0.08166</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>10:19:13</td>     <th>  Log-Likelihood:    </th> <td> -227.82</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -248.08</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>1.176e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre</th>       <td>    0.0022</td> <td>    0.001</td> <td>    2.028</td> <td> 0.043</td> <td> 7.44e-05     0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa</th>       <td>    0.7793</td> <td>    0.333</td> <td>    2.344</td> <td> 0.019</td> <td>    0.128     1.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>two</th>       <td>   -0.6801</td> <td>    0.317</td> <td>   -2.146</td> <td> 0.032</td> <td>   -1.301    -0.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>three</th>     <td>   -1.3387</td> <td>    0.345</td> <td>   -3.882</td> <td> 0.000</td> <td>   -2.015    -0.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>four</th>      <td>   -1.5534</td> <td>    0.417</td> <td>   -3.721</td> <td> 0.000</td> <td>   -2.372    -0.735</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th> <td>   -3.8769</td> <td>    1.142</td> <td>   -3.393</td> <td> 0.001</td> <td>   -6.116    -1.638</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  397\n",
       "Model:                          Logit   Df Residuals:                      391\n",
       "Method:                           MLE   Df Model:                            5\n",
       "Date:                Sun, 11 Jun 2017   Pseudo R-squ.:                 0.08166\n",
       "Time:                        10:19:13   Log-Likelihood:                -227.82\n",
       "converged:                       True   LL-Null:                       -248.08\n",
       "                                        LLR p-value:                 1.176e-07\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "gre            0.0022      0.001      2.028      0.043      7.44e-05     0.004\n",
       "gpa            0.7793      0.333      2.344      0.019         0.128     1.431\n",
       "two           -0.6801      0.317     -2.146      0.032        -1.301    -0.059\n",
       "three         -1.3387      0.345     -3.882      0.000        -2.015    -0.663\n",
       "four          -1.5534      0.417     -3.721      0.000        -2.372    -0.735\n",
       "intercept     -3.8769      1.142     -3.393      0.001        -6.116    -1.638\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['intercept'] = 1.0\n",
    "smf.Logit(admit, X).fit().summary()\n",
    "# Now everything is significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 14.  What are the odds ratios of the different features and their 95% confidence intervals?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573854\n",
      "         Iterations 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gre</th>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.004362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpa</th>\n",
       "      <td>0.127619</td>\n",
       "      <td>1.431056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>two</th>\n",
       "      <td>-1.301337</td>\n",
       "      <td>-0.058936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>-2.014579</td>\n",
       "      <td>-0.662776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>four</th>\n",
       "      <td>-2.371624</td>\n",
       "      <td>-0.735197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intercept</th>\n",
       "      <td>-6.116077</td>\n",
       "      <td>-1.637631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1\n",
       "gre        0.000074  0.004362\n",
       "gpa        0.127619  1.431056\n",
       "two       -1.301337 -0.058936\n",
       "three     -2.014579 -0.662776\n",
       "four      -2.371624 -0.735197\n",
       "intercept -6.116077 -1.637631"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.Logit(admit, X).fit().conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.573854\n",
      "         Iterations 6\n",
      "gre          1.002221\n",
      "gpa          2.180027\n",
      "two          0.506548\n",
      "three        0.262192\n",
      "four         0.211525\n",
      "intercept    0.020716\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "print np.exp(smf.Logit(admit, X).fit().params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 15.  Interpret the odds ratio for `prestige = 2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Compared to going to a prestige 1 school, a prestige 2 school is half as likely to get in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 16.  Interpret the odds ratio of `gpa`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: A unit increase in gpa makes it more than twice as likely to get in compared with the unit below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 17.  Assuming a student with a GRE of 800 and a GPA of 4.  What is his/her probability of admission  if he/she come from a tier-1, tier-2, tier-3, or tier-4 undergraduate school?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.589121\n",
      "         Iterations 5\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-dbfd75653e65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLogit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madmit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'gre'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m800\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gpa'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;36m4.0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "result = smf.Logit(admit, X).fit()\n",
    "result.predict(X({'gre' : 800, 'gpa' : 4.0}), transform=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part E. Moving the model from `statsmodels` to `sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 18.  Let's assume we are satisfied with our model.  Remodel it (same features) using `sklearn`.  When creating the logistic regression model with `LogisticRegression(C = 10 ** 2)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00215822  0.67315495 -0.62882239 -1.25222745 -1.56879212]]\n",
      "[-3.51478687]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "admit = df.admit\n",
    "X = df[['gre', 'gpa', 'two', 'three', 'four']]\n",
    "model_admit = linear_model.LogisticRegression(C = 10 **2).fit(X, admit)\n",
    "print model_admit.coef_\n",
    "print model_admit.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 19.  What are the odds ratios for the different variables and how do they compare with the odds ratios calculated with `statsmodels`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.00216055  1.96041259  0.53321936  0.28586733  0.20829663]]\n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "print np.exp(model_admit.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: They are slightly different which could be rounding error or the difference in how things are calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Question 20.  Again, assuming a student with a GRE of 800 and a GPA of 4.  What is his/her probability of admission  if he/she come from a tier-1, tier-2, tier-3, or tier-4 undergraduate school?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.82006723,  0.17993277],\n",
       "       [ 0.70518527,  0.29481473],\n",
       "       [ 0.28814605,  0.71185395],\n",
       "       [ 0.8256285 ,  0.1743715 ],\n",
       "       [ 0.87963338,  0.12036662],\n",
       "       [ 0.61866854,  0.38133146],\n",
       "       [ 0.57448761,  0.42551239],\n",
       "       [ 0.76976874,  0.23023126],\n",
       "       [ 0.78911227,  0.21088773],\n",
       "       [ 0.49852276,  0.50147724],\n",
       "       [ 0.66024514,  0.33975486],\n",
       "       [ 0.59811405,  0.40188595],\n",
       "       [ 0.30617208,  0.69382792],\n",
       "       [ 0.63634638,  0.36365362],\n",
       "       [ 0.3343482 ,  0.6656518 ],\n",
       "       [ 0.80461908,  0.19538092],\n",
       "       [ 0.68891705,  0.31108295],\n",
       "       [ 0.90608816,  0.09391184],\n",
       "       [ 0.47320216,  0.52679784],\n",
       "       [ 0.4463647 ,  0.5536353 ],\n",
       "       [ 0.82549148,  0.17450852],\n",
       "       [ 0.56847566,  0.43152434],\n",
       "       [ 0.86879575,  0.13120425],\n",
       "       [ 0.81284879,  0.18715121],\n",
       "       [ 0.56175715,  0.43824285],\n",
       "       [ 0.33725911,  0.66274089],\n",
       "       [ 0.43698779,  0.56301221],\n",
       "       [ 0.80902811,  0.19097189],\n",
       "       [ 0.57264288,  0.42735712],\n",
       "       [ 0.54434196,  0.45565804],\n",
       "       [ 0.7979639 ,  0.2020361 ],\n",
       "       [ 0.70509962,  0.29490038],\n",
       "       [ 0.76555108,  0.23444892],\n",
       "       [ 0.58608936,  0.41391064],\n",
       "       [ 0.65115562,  0.34884438],\n",
       "       [ 0.77332822,  0.22667178],\n",
       "       [ 0.5188082 ,  0.4811918 ],\n",
       "       [ 0.84456485,  0.15543515],\n",
       "       [ 0.7226263 ,  0.2773737 ],\n",
       "       [ 0.86302994,  0.13697006],\n",
       "       [ 0.78683862,  0.21316138],\n",
       "       [ 0.65857938,  0.34142062],\n",
       "       [ 0.67441935,  0.32558065],\n",
       "       [ 0.81149653,  0.18850347],\n",
       "       [ 0.65786242,  0.34213758],\n",
       "       [ 0.81028308,  0.18971692],\n",
       "       [ 0.63708355,  0.36291645],\n",
       "       [ 0.88134208,  0.11865792],\n",
       "       [ 0.92161825,  0.07838175],\n",
       "       [ 0.83870974,  0.16129026],\n",
       "       [ 0.68726813,  0.31273187],\n",
       "       [ 0.88360178,  0.11639822],\n",
       "       [ 0.77170565,  0.22829435],\n",
       "       [ 0.61652066,  0.38347934],\n",
       "       [ 0.74918204,  0.25081796],\n",
       "       [ 0.61711367,  0.38288633],\n",
       "       [ 0.80393141,  0.19606859],\n",
       "       [ 0.87737643,  0.12262357],\n",
       "       [ 0.69493798,  0.30506202],\n",
       "       [ 0.86879575,  0.13120425],\n",
       "       [ 0.66035642,  0.33964358],\n",
       "       [ 0.83754908,  0.16245092],\n",
       "       [ 0.71407894,  0.28592106],\n",
       "       [ 0.66991071,  0.33008929],\n",
       "       [ 0.69479424,  0.30520576],\n",
       "       [ 0.60636397,  0.39363603],\n",
       "       [ 0.74071318,  0.25928682],\n",
       "       [ 0.48882235,  0.51117765],\n",
       "       [ 0.44499357,  0.55500643],\n",
       "       [ 0.32680894,  0.67319106],\n",
       "       [ 0.66666432,  0.33333568],\n",
       "       [ 0.92204785,  0.07795215],\n",
       "       [ 0.85391466,  0.14608534],\n",
       "       [ 0.54964204,  0.45035796],\n",
       "       [ 0.7698172 ,  0.2301828 ],\n",
       "       [ 0.62725986,  0.37274014],\n",
       "       [ 0.78526441,  0.21473559],\n",
       "       [ 0.58608936,  0.41391064],\n",
       "       [ 0.56195671,  0.43804329],\n",
       "       [ 0.37380524,  0.62619476],\n",
       "       [ 0.83488873,  0.16511127],\n",
       "       [ 0.67676183,  0.32323817],\n",
       "       [ 0.77560781,  0.22439219],\n",
       "       [ 0.90925533,  0.09074467],\n",
       "       [ 0.77980816,  0.22019184],\n",
       "       [ 0.73406301,  0.26593699],\n",
       "       [ 0.64880841,  0.35119159],\n",
       "       [ 0.62389196,  0.37610804],\n",
       "       [ 0.44919786,  0.55080214],\n",
       "       [ 0.50664142,  0.49335858],\n",
       "       [ 0.51366534,  0.48633466],\n",
       "       [ 0.38003203,  0.61996797],\n",
       "       [ 0.44812054,  0.55187946],\n",
       "       [ 0.71494028,  0.28505972],\n",
       "       [ 0.59953645,  0.40046355],\n",
       "       [ 0.61717652,  0.38282348],\n",
       "       [ 0.791306  ,  0.208694  ],\n",
       "       [ 0.66918531,  0.33081469],\n",
       "       [ 0.66689441,  0.33310559],\n",
       "       [ 0.84231906,  0.15768094],\n",
       "       [ 0.87133148,  0.12866852],\n",
       "       [ 0.75251784,  0.24748216],\n",
       "       [ 0.88307228,  0.11692772],\n",
       "       [ 0.72098393,  0.27901607],\n",
       "       [ 0.5150517 ,  0.4849483 ],\n",
       "       [ 0.63349957,  0.36650043],\n",
       "       [ 0.40314075,  0.59685925],\n",
       "       [ 0.73119439,  0.26880561],\n",
       "       [ 0.87340254,  0.12659746],\n",
       "       [ 0.68681723,  0.31318277],\n",
       "       [ 0.82385329,  0.17614671],\n",
       "       [ 0.86780284,  0.13219716],\n",
       "       [ 0.87767468,  0.12232532],\n",
       "       [ 0.51307169,  0.48692831],\n",
       "       [ 0.65207762,  0.34792238],\n",
       "       [ 0.67765862,  0.32234138],\n",
       "       [ 0.70508057,  0.29491943],\n",
       "       [ 0.53213615,  0.46786385],\n",
       "       [ 0.33126731,  0.66873269],\n",
       "       [ 0.88771482,  0.11228518],\n",
       "       [ 0.6233373 ,  0.3766627 ],\n",
       "       [ 0.7875704 ,  0.2124296 ],\n",
       "       [ 0.84893221,  0.15106779],\n",
       "       [ 0.8431566 ,  0.1568434 ],\n",
       "       [ 0.64594406,  0.35405594],\n",
       "       [ 0.83792629,  0.16207371],\n",
       "       [ 0.45931244,  0.54068756],\n",
       "       [ 0.7249002 ,  0.2750998 ],\n",
       "       [ 0.69652588,  0.30347412],\n",
       "       [ 0.87764997,  0.12235003],\n",
       "       [ 0.66186458,  0.33813542],\n",
       "       [ 0.70770196,  0.29229804],\n",
       "       [ 0.64636921,  0.35363079],\n",
       "       [ 0.83404758,  0.16595242],\n",
       "       [ 0.72095457,  0.27904543],\n",
       "       [ 0.78325613,  0.21674387],\n",
       "       [ 0.83663109,  0.16336891],\n",
       "       [ 0.6372952 ,  0.3627048 ],\n",
       "       [ 0.62639659,  0.37360341],\n",
       "       [ 0.45263318,  0.54736682],\n",
       "       [ 0.52917991,  0.47082009],\n",
       "       [ 0.76911536,  0.23088464],\n",
       "       [ 0.74899415,  0.25100585],\n",
       "       [ 0.77320936,  0.22679064],\n",
       "       [ 0.82391307,  0.17608693],\n",
       "       [ 0.83725866,  0.16274134],\n",
       "       [ 0.69401107,  0.30598893],\n",
       "       [ 0.84994424,  0.15005576],\n",
       "       [ 0.62713901,  0.37286099],\n",
       "       [ 0.42300846,  0.57699154],\n",
       "       [ 0.3253297 ,  0.6746703 ],\n",
       "       [ 0.73205214,  0.26794786],\n",
       "       [ 0.52750243,  0.47249757],\n",
       "       [ 0.76604878,  0.23395122],\n",
       "       [ 0.72010429,  0.27989571],\n",
       "       [ 0.87063567,  0.12936433],\n",
       "       [ 0.77533036,  0.22466964],\n",
       "       [ 0.51723036,  0.48276964],\n",
       "       [ 0.59142908,  0.40857092],\n",
       "       [ 0.66481175,  0.33518825],\n",
       "       [ 0.67736858,  0.32263142],\n",
       "       [ 0.60020253,  0.39979747],\n",
       "       [ 0.55883291,  0.44116709],\n",
       "       [ 0.76559882,  0.23440118],\n",
       "       [ 0.6616001 ,  0.3383999 ],\n",
       "       [ 0.3343482 ,  0.6656518 ],\n",
       "       [ 0.8757671 ,  0.1242329 ],\n",
       "       [ 0.66269003,  0.33730997],\n",
       "       [ 0.7301309 ,  0.2698691 ],\n",
       "       [ 0.73793518,  0.26206482],\n",
       "       [ 0.8236034 ,  0.1763966 ],\n",
       "       [ 0.84683791,  0.15316209],\n",
       "       [ 0.7224904 ,  0.2775096 ],\n",
       "       [ 0.52700256,  0.47299744],\n",
       "       [ 0.83592761,  0.16407239],\n",
       "       [ 0.63111042,  0.36888958],\n",
       "       [ 0.77862497,  0.22137503],\n",
       "       [ 0.77810035,  0.22189965],\n",
       "       [ 0.76626047,  0.23373953],\n",
       "       [ 0.89025547,  0.10974453],\n",
       "       [ 0.70773215,  0.29226785],\n",
       "       [ 0.80101178,  0.19898822],\n",
       "       [ 0.4850641 ,  0.5149359 ],\n",
       "       [ 0.59706673,  0.40293327],\n",
       "       [ 0.89343981,  0.10656019],\n",
       "       [ 0.49841978,  0.50158022],\n",
       "       [ 0.75552952,  0.24447048],\n",
       "       [ 0.70441743,  0.29558257],\n",
       "       [ 0.69198855,  0.30801145],\n",
       "       [ 0.6863857 ,  0.3136143 ],\n",
       "       [ 0.6586926 ,  0.3413074 ],\n",
       "       [ 0.70155085,  0.29844915],\n",
       "       [ 0.86375458,  0.13624542],\n",
       "       [ 0.6254702 ,  0.3745298 ],\n",
       "       [ 0.62676942,  0.37323058],\n",
       "       [ 0.78176922,  0.21823078],\n",
       "       [ 0.88554305,  0.11445695],\n",
       "       [ 0.73663131,  0.26336869],\n",
       "       [ 0.78482682,  0.21517318],\n",
       "       [ 0.69259921,  0.30740079],\n",
       "       [ 0.67650331,  0.32349669],\n",
       "       [ 0.3343482 ,  0.6656518 ],\n",
       "       [ 0.82322635,  0.17677365],\n",
       "       [ 0.40162108,  0.59837892],\n",
       "       [ 0.62846038,  0.37153962],\n",
       "       [ 0.38573849,  0.61426151],\n",
       "       [ 0.42310901,  0.57689099],\n",
       "       [ 0.81372651,  0.18627349],\n",
       "       [ 0.63083531,  0.36916469],\n",
       "       [ 0.77524393,  0.22475607],\n",
       "       [ 0.7024342 ,  0.2975658 ],\n",
       "       [ 0.75222095,  0.24777905],\n",
       "       [ 0.61117367,  0.38882633],\n",
       "       [ 0.79958638,  0.20041362],\n",
       "       [ 0.6961105 ,  0.3038895 ],\n",
       "       [ 0.51792325,  0.48207675],\n",
       "       [ 0.62621336,  0.37378664],\n",
       "       [ 0.62676942,  0.37323058],\n",
       "       [ 0.80117108,  0.19882892],\n",
       "       [ 0.6487478 ,  0.3512522 ],\n",
       "       [ 0.60966767,  0.39033233],\n",
       "       [ 0.6692056 ,  0.3307944 ],\n",
       "       [ 0.614173  ,  0.385827  ],\n",
       "       [ 0.70204538,  0.29795462],\n",
       "       [ 0.59763509,  0.40236491],\n",
       "       [ 0.86820895,  0.13179105],\n",
       "       [ 0.68970582,  0.31029418],\n",
       "       [ 0.57138501,  0.42861499],\n",
       "       [ 0.83439953,  0.16560047],\n",
       "       [ 0.77973742,  0.22026258],\n",
       "       [ 0.74043365,  0.25956635],\n",
       "       [ 0.88727864,  0.11272136],\n",
       "       [ 0.35708872,  0.64291128],\n",
       "       [ 0.67969992,  0.32030008],\n",
       "       [ 0.6022972 ,  0.3977028 ],\n",
       "       [ 0.88886978,  0.11113022],\n",
       "       [ 0.71786157,  0.28213843],\n",
       "       [ 0.79184568,  0.20815432],\n",
       "       [ 0.45705469,  0.54294531],\n",
       "       [ 0.78699214,  0.21300786],\n",
       "       [ 0.65429143,  0.34570857],\n",
       "       [ 0.57516583,  0.42483417],\n",
       "       [ 0.60070563,  0.39929437],\n",
       "       [ 0.60532078,  0.39467922],\n",
       "       [ 0.74270837,  0.25729163],\n",
       "       [ 0.7003875 ,  0.2996125 ],\n",
       "       [ 0.70576187,  0.29423813],\n",
       "       [ 0.80705925,  0.19294075],\n",
       "       [ 0.8298632 ,  0.1701368 ],\n",
       "       [ 0.58144727,  0.41855273],\n",
       "       [ 0.82177833,  0.17822167],\n",
       "       [ 0.75343073,  0.24656927],\n",
       "       [ 0.75596572,  0.24403428],\n",
       "       [ 0.68995863,  0.31004137],\n",
       "       [ 0.68351196,  0.31648804],\n",
       "       [ 0.65893759,  0.34106241],\n",
       "       [ 0.54924756,  0.45075244],\n",
       "       [ 0.64164495,  0.35835505],\n",
       "       [ 0.74527265,  0.25472735],\n",
       "       [ 0.81718309,  0.18281691],\n",
       "       [ 0.68351196,  0.31648804],\n",
       "       [ 0.73486311,  0.26513689],\n",
       "       [ 0.8453459 ,  0.1546541 ],\n",
       "       [ 0.84474374,  0.15525626],\n",
       "       [ 0.73532327,  0.26467673],\n",
       "       [ 0.58586724,  0.41413276],\n",
       "       [ 0.85770297,  0.14229703],\n",
       "       [ 0.52582433,  0.47417567],\n",
       "       [ 0.79575515,  0.20424485],\n",
       "       [ 0.55120587,  0.44879413],\n",
       "       [ 0.4639353 ,  0.5360647 ],\n",
       "       [ 0.71526492,  0.28473508],\n",
       "       [ 0.69902898,  0.30097102],\n",
       "       [ 0.77494392,  0.22505608],\n",
       "       [ 0.46334766,  0.53665234],\n",
       "       [ 0.83153252,  0.16846748],\n",
       "       [ 0.64690916,  0.35309084],\n",
       "       [ 0.51673289,  0.48326711],\n",
       "       [ 0.85678501,  0.14321499],\n",
       "       [ 0.79195863,  0.20804137],\n",
       "       [ 0.86698118,  0.13301882],\n",
       "       [ 0.71340908,  0.28659092],\n",
       "       [ 0.82642607,  0.17357393],\n",
       "       [ 0.40628502,  0.59371498],\n",
       "       [ 0.76287079,  0.23712921],\n",
       "       [ 0.77496615,  0.22503385],\n",
       "       [ 0.93436747,  0.06563253],\n",
       "       [ 0.61848697,  0.38151303],\n",
       "       [ 0.63312952,  0.36687048],\n",
       "       [ 0.54620516,  0.45379484],\n",
       "       [ 0.29230599,  0.70769401],\n",
       "       [ 0.68185252,  0.31814748],\n",
       "       [ 0.81107167,  0.18892833],\n",
       "       [ 0.54463501,  0.45536499],\n",
       "       [ 0.74729637,  0.25270363],\n",
       "       [ 0.65070296,  0.34929704],\n",
       "       [ 0.71593217,  0.28406783],\n",
       "       [ 0.63203107,  0.36796893],\n",
       "       [ 0.71488606,  0.28511394],\n",
       "       [ 0.76131181,  0.23868819],\n",
       "       [ 0.49921651,  0.50078349],\n",
       "       [ 0.91584435,  0.08415565],\n",
       "       [ 0.81797651,  0.18202349],\n",
       "       [ 0.55365495,  0.44634505],\n",
       "       [ 0.62926628,  0.37073372],\n",
       "       [ 0.7049949 ,  0.2950051 ],\n",
       "       [ 0.85953072,  0.14046928],\n",
       "       [ 0.70386974,  0.29613026],\n",
       "       [ 0.56185857,  0.43814143],\n",
       "       [ 0.69099987,  0.30900013],\n",
       "       [ 0.81821365,  0.18178635],\n",
       "       [ 0.8304791 ,  0.1695209 ],\n",
       "       [ 0.82982458,  0.17017542],\n",
       "       [ 0.8006483 ,  0.1993517 ],\n",
       "       [ 0.72244426,  0.27755574],\n",
       "       [ 0.82494705,  0.17505295],\n",
       "       [ 0.53529179,  0.46470821],\n",
       "       [ 0.84030896,  0.15969104],\n",
       "       [ 0.67720037,  0.32279963],\n",
       "       [ 0.87849714,  0.12150286],\n",
       "       [ 0.80633539,  0.19366461],\n",
       "       [ 0.86143068,  0.13856932],\n",
       "       [ 0.35936899,  0.64063101],\n",
       "       [ 0.61013504,  0.38986496],\n",
       "       [ 0.64392236,  0.35607764],\n",
       "       [ 0.65554574,  0.34445426],\n",
       "       [ 0.88412918,  0.11587082],\n",
       "       [ 0.61711367,  0.38288633],\n",
       "       [ 0.71625613,  0.28374387],\n",
       "       [ 0.6492622 ,  0.3507378 ],\n",
       "       [ 0.77721194,  0.22278806],\n",
       "       [ 0.78983833,  0.21016167],\n",
       "       [ 0.42050234,  0.57949766],\n",
       "       [ 0.82117142,  0.17882858],\n",
       "       [ 0.84096646,  0.15903354],\n",
       "       [ 0.54865918,  0.45134082],\n",
       "       [ 0.73238255,  0.26761745],\n",
       "       [ 0.86178326,  0.13821674],\n",
       "       [ 0.85502297,  0.14497703],\n",
       "       [ 0.79339447,  0.20660553],\n",
       "       [ 0.69677557,  0.30322443],\n",
       "       [ 0.80054007,  0.19945993],\n",
       "       [ 0.838654  ,  0.161346  ],\n",
       "       [ 0.64419323,  0.35580677],\n",
       "       [ 0.58269718,  0.41730282],\n",
       "       [ 0.73468469,  0.26531531],\n",
       "       [ 0.70827566,  0.29172434],\n",
       "       [ 0.44215551,  0.55784449],\n",
       "       [ 0.75398858,  0.24601142],\n",
       "       [ 0.80455431,  0.19544569],\n",
       "       [ 0.56546036,  0.43453964],\n",
       "       [ 0.60674425,  0.39325575],\n",
       "       [ 0.49574453,  0.50425547],\n",
       "       [ 0.60626564,  0.39373436],\n",
       "       [ 0.43357715,  0.56642285],\n",
       "       [ 0.74544642,  0.25455358],\n",
       "       [ 0.63665352,  0.36334648],\n",
       "       [ 0.42553182,  0.57446818],\n",
       "       [ 0.50000994,  0.49999006],\n",
       "       [ 0.6369883 ,  0.3630117 ],\n",
       "       [ 0.69744849,  0.30255151],\n",
       "       [ 0.51109457,  0.48890543],\n",
       "       [ 0.86526199,  0.13473801],\n",
       "       [ 0.85837899,  0.14162101],\n",
       "       [ 0.7281721 ,  0.2718279 ],\n",
       "       [ 0.39422235,  0.60577765],\n",
       "       [ 0.44978588,  0.55021412],\n",
       "       [ 0.60834928,  0.39165072],\n",
       "       [ 0.68316715,  0.31683285],\n",
       "       [ 0.60304416,  0.39695584],\n",
       "       [ 0.4770564 ,  0.5229436 ],\n",
       "       [ 0.59639894,  0.40360106],\n",
       "       [ 0.82137154,  0.17862846],\n",
       "       [ 0.58951559,  0.41048441],\n",
       "       [ 0.43153702,  0.56846298],\n",
       "       [ 0.78338675,  0.21661325],\n",
       "       [ 0.76145163,  0.23854837],\n",
       "       [ 0.54384779,  0.45615221],\n",
       "       [ 0.65223141,  0.34776859],\n",
       "       [ 0.64917141,  0.35082859],\n",
       "       [ 0.35382793,  0.64617207],\n",
       "       [ 0.79314695,  0.20685305],\n",
       "       [ 0.6400102 ,  0.3599898 ],\n",
       "       [ 0.48704083,  0.51295917],\n",
       "       [ 0.65249936,  0.34750064],\n",
       "       [ 0.65213796,  0.34786204],\n",
       "       [ 0.59858614,  0.40141386],\n",
       "       [ 0.58998765,  0.41001235],\n",
       "       [ 0.52681072,  0.47318928],\n",
       "       [ 0.76795883,  0.23204117],\n",
       "       [ 0.56983662,  0.43016338],\n",
       "       [ 0.74807031,  0.25192969],\n",
       "       [ 0.52819403,  0.47180597],\n",
       "       [ 0.81936077,  0.18063923],\n",
       "       [ 0.79906047,  0.20093953],\n",
       "       [ 0.54384779,  0.45615221],\n",
       "       [ 0.70130341,  0.29869659]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "model_admit.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part F.  Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 21.  Introduction\n",
    ">\n",
    "> Write a problem statement for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Our graduate programs have seen a marked increase in the amount of applications received each year. To better handle the increased volume we need to reassess our standards and look at the prior candidate pools and which attribute contributed to their acceptance into our school. We need to have a new process and standards at least 3 months before the next application deadline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 22.  Dataset\n",
    ">\n",
    "> Write up a description of your data and any cleaning that was completed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: We have 3 variable on which to predict admission. gre is the GRE score. gpa is the student's undergraduate GPA. And prestige is the level of prestige of the alma mater classified into 4 levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable | Description | Type of Variable\n",
    "---|---|---\n",
    "admit | 0 = Not admitted, 1 = Admitted | Categorical\n",
    "gre | Score on Graduate Record Examination | Discrete\n",
    "gpa | Score of Grade Point Average | Continuous\n",
    "prestige | Prestige of alma mater (4 = lowest, 1 = highest) | Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "> ## Question 23.  Demo\n",
    ">\n",
    "> Provide a table that explains the data by admission status."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 24.  Methods\n",
    ">\n",
    "> Write up the methods used in your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: Our goal for our problem is to better understand who we admit, so for our analysis we utilized logistic regression. With 'prestige' as our categorical variable we needed to split it up so we could see the effect of each level separately, so we created dummy variables. With dummy variables we were able to run our regression and find coeficients for our variables. With our coeficients and odds ratios we are able to predict whether we will admit a student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 25.  Results\n",
    ">\n",
    "> Write up your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 26.  Visuals\n",
    ">\n",
    "> Provide a table or visualization of these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Question 27.  Discussion\n",
    ">\n",
    "> Write up your discussion and future steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
