{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuition for Regularization\n",
    "\n",
    "Okay, so you understand regression like a champion, but something tells you that these models are not a cure-all that explain all data. Big data sets are notorious for growing complex and creating extreme explanations for the data they describe. Even if these extreme explantions fit the data better than a simpler model, they are less likely to be  generalized. These models explain data from the past well, but are less likely to explain for future data it has never seen before. This issue, as you probably heard, is called an overfit model.\n",
    "\n",
    "Take this trivial example: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table border=\"1\" class=\"dataframe\">   <thead>     <tr style=\"text-align: right;\">       <th></th>       <th>animal</th>       <th>size</th>       <th>label</th>     </tr>   </thead>   <tbody>     <tr>       <th>Bo</th>       <td>snake</td>       <td>small</td>       <td>friendly</td>     </tr>     <tr>       <th>Spot</th>       <td>dog</td>       <td>small</td>       <td>friendly</td>     </tr>     <tr>       <th>Mo</th>       <td>cat</td>       <td>small</td>       <td>enemy</td>     </tr>     <tr>       <th>Lefty</th>       <td>cat</td>       <td>small</td>       <td>friendly</td>     </tr>     <tr>       <th>Curly</th>       <td>dog</td>       <td>large</td>       <td>friendly</td>     </tr>     <tr>       <th>Tom</th>       <td>snail</td>       <td>small</td>       <td>friendly</td>     </tr>     <tr>       <th>Jerry</th>       <td>dog</td>       <td>large</td>       <td>enemy</td>     </tr>     <tr>       <th>Sylvester</th>       <td>cat</td>       <td>large</td>       <td>enemy</td>     </tr>   </tbody> </table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model builds the rule:\n",
    "\n",
    "    \"pets with up to four-letter names are enemies, as are large dogs with names beginning with 'J', except that small snakes are not enemies\"\n",
    "\n",
    "The model is dumb. Yes, it fits perfectly, but its clunky. Intuitively, we know this will not generalize out to all the pets in the real world. There must be a simpler rule. Consider this:\n",
    "\n",
    "    \"large dogs and cats are enemies\"\n",
    "\n",
    "It does not fit the data perfectly, but fits reasonably well. It's simpler, and we may suppose that this rule will better hold true to thousands more examples.\n",
    "\n",
    "Regularization prevents this overfitting. Loosely, regularization is a technique to discourage complexity and increase  generalization, and it sometimes comes at the cost of model accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Okay\", you say. I'm ready for level 2.\n",
    "\n",
    "### Underfitting \n",
    "First - a quick note on underfitting. This is the condition where our model is not able to find any relationship between inputs and outputs. Our model cannot find any corelation between a pet's characteristics and friendliness. Underfitting is intuitive to catch, just look at the classification accuracy on the training data. If the accuracy is low, the model may be too simple, and therefore underfit. Increase the complexity (the number of paramters in the model), and get a better fit. As we will see, regularization also helps alleviate this problem. \n",
    "\n",
    "### Overfitting \n",
    "On the other end of the spectrum, overfitting is more difficult to detect. You must monitor when your model is performing _too_ well on training data, and poorly on testing data. \n",
    "\n",
    "Regularization will help the model find a happy medium between these two states, and minimize the overall prediction error. It tweaks the model to avoid being too simple, avoid being too complex, and find something juuuuust right. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/momonala/DS_tutorials/master/files/bias_variance_tradeoff_e.jpg\">\n",
    "<center>\n",
    "    ** Figure 1 **\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization \n",
    "\n",
    "So how do we implement regularization? It is acheived by penalzing the weights in our model. Let's take a high level look at our model: \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/momonala/DS_tutorials/master/files/model_matrix.png\" width='600'>\n",
    "<center>\n",
    "    ** Figure 2 **\n",
    "</center>\n",
    "\n",
    "In this infographic, there are four parameters to our model: \n",
    "\n",
    "    1) x: The input data with i (height) data points and j (width) features\n",
    "    2) y: The labels \n",
    "    3) ŷ: The predictions (what our model outputs)\n",
    "    4) W: The weights of the \"j\" coefficents\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/momonala/DS_tutorials/master/files/prediction_eq.png'>\n",
    "\n",
    "\n",
    "\n",
    "In mathematical terms, our prediction, ŷ, equals the weighted sum of the data points. \n",
    "\n",
    "### Penalizing Weights\n",
    "\n",
    "Regularization penalizes the weights, W, of our model, above. How does this help? In Figure 1 we learned that after a point, increasing model complexity is bad for the prediction accuracy. The model complexity prevents generalization by contouring to very small deviations in the data. \n",
    "\n",
    "Another way to think of it is that smaller coefficients are considered less complex because they say less about the world - they make weaker statements. Think about how the two statements on animal friendliness differ. \"Complexity\" may not be the ideal term; its a shame statistics don't take courses in etymology.\n",
    "\n",
    "The key point is that **the size of the coeffient weights, W, increases with model complexity**. The magnitude of the coefficient represents the emphasis we are putting on that feature as a predictor. If we think animal size is important to friendliness, we will give that feature a large weight.  \n",
    "\n",
    "\n",
    "\n",
    "Penalizing the weights constrains them, and helps generalize the predictions our model makes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 Ridge Regression\n",
    "\n",
    "Ridge Regresssion is the most common type of regularization penalty. It is calculated as the sum of the squares of the weights. Here we see the equation for the L2 penalty. Later I will cover how to implement it into the model. \n",
    "\n",
    "<img src='https://raw.githubusercontent.com/momonala/DS_tutorials/master/files/l2_eq.png'>\n",
    "\n",
    "we can gain an intuition of it in python: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "penalty = 0 #initialzie to zero, R(W) in the equation above\n",
    "W = np.zeros(shape=(10,10)) #fake weights matrix\n",
    "\n",
    "for i in np.arange(0, W.shape[0]):\n",
    "    for j in np.arange(0, W.shape[1]):\n",
    "        penalty += (W[i][j]**2)#square the weights and add "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we are looping over the entire weights matrix and summing the squares of the weights. We can do this more efficiently with linear algebra, but this is just for demonstration. As an exponential function, you can see that L2 will penalize large weights from our W matrix, and prefer smaller ones. This will seek out W values that represent all features of the data. \n",
    "\n",
    "We should note that L2 is primarily used to prevent overfitting. The result keeps all the features in the model, but may reduce their weight. This is not true of all types of regulariztion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1 Lasso Regression\n",
    "\n",
    "L1 takes the absolute value rather than the square:\n",
    "\n",
    "<img src='https://raw.githubusercontent.com/momonala/DS_tutorials/master/files/l1_eq.png'>\n",
    "\n",
    "L1 regularization shrinks coefficients, like L2, but it may also reduce some coefficents to zero, which is unique. A coeficent of zero essentially means that feature has been removed from the model. This is useful in senarios where we have hundres or thousands of features, like image classification, but may be excessive for smaller needs. \n",
    "\n",
    "we can gain an intuition of L1 in python: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "penalty = 0 #initialzie to zero, R(W) in the equation above\n",
    "W = np.zeros(shape=(10,10)) #fake weights matrix\n",
    "\n",
    "for i in np.arange(0, W.shape[0]):\n",
    "    for j in np.arange(0, W.shape[1]):\n",
    "        penalty += (abs(W[i][j]))#absolute value the weights and add "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a few other types of regularization (Elastic Net, Dropout) used for other models. The key takeway is that we have calculated an R(W) penalty term. \n",
    "\n",
    "# Loss Function\n",
    "\n",
    "We must now add this term to our loss function (also called cost function or objective function). The loss function maps our model performance to some \"real-world\" interpretation, where we can measure its error as a \"cost\". Our goal is to minimize that cost; minimize the error.  Quantitatively, the loss function answers the following: \n",
    "\n",
    "    \"The real label was 1, but I predicted 0. Is that bad?\" \n",
    "    \"Yeah. That's bad. 500 bad, to be specific.\"\n",
    "\n",
    "Or \"X bad\", where X is the measure of the cost. Mathematically, this is the most basic form of the loss function: \n",
    "\n",
    "<img src='https://raw.githubusercontent.com/momonala/DS_tutorials/master/files/loss_func.png' width='150'>\n",
    "\n",
    "To implement regularization, we multiply our penalty term, R(W), by a coefficent λ, and add that  to the loss function. \n",
    "\n",
    "<img src='https://raw.githubusercontent.com/momonala/DS_tutorials/master/files/loss_func_add_reg.png' width='220'>\n",
    "\n",
    "λ is a hyperparamter, which means that it is a variable that _**we**_ set, unlike the weights, W, or predictions ŷ. We can also tune λ like a radio dial, and set it to value that gives us the best results. If cleaning up data is the thing you do most in data science, then tuning hyperparameters is the thing you do second most. \n",
    "\n",
    "And that's it! We update weights in the loss function, to minimize our prediction error. In doing this, we have reduced the magnitude of the coefficeints, and therefore reduced the model complexity. The trick comes in idenifying when and how to implement regularization. \n",
    "\n",
    "# Python Implementation\n",
    "\n",
    "Here I use the university admit dataset that determines if a student will get into grad school based on GPA, GRE, and the prestige of their undergrad almamater. I use sklearn's logisitc regression function to classify whether a student will get into the university, and try out the corresponding regularization types with the \"penalty\" argument. Note that the only two options here are L1 and L2 (no none option), and the default setting is L2. Though you can not \"turn off\" regularization with sklearn, you can just tune its stregth to be very low, as explained later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "data = pd.read_csv(\"https://stats.idre.ucla.edu/stat/data/binary.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add dummies\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank_1</th>\n",
       "      <th>rank_2</th>\n",
       "      <th>rank_3</th>\n",
       "      <th>rank_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank_1  rank_2  rank_3  rank_4\n",
       "0      0  380  3.61       0       0       1       0\n",
       "1      1  660  3.67       0       0       1       0\n",
       "2      1  800  4.00       1       0       0       0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dummy variables (categorical) for logistic regression \n",
    "#add to original dataframe \n",
    "dummy_ranks = pd.get_dummies(data['rank'], prefix='rank')\n",
    "cols_to_keep = ['admit', 'gre', 'gpa']\n",
    "df = data[cols_to_keep].join(dummy_ranks)\n",
    "print \"add dummies\"\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty:  l1\n",
      "accuracy 0.67\n",
      "weights:  [[  1.01840370e-03   2.12057457e-01   1.10840207e+00   6.20089456e-01\n",
      "    0.00000000e+00]]\n",
      "\n",
      "penalty:  l2\n",
      "accuracy 0.65\n",
      "weights:  [[  5.36604799e-04   8.84567691e-02   1.01122051e+00   5.32212066e-01\n",
      "   -1.55149010e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import  train_test_split\n",
    "\n",
    "#note that I remove prestige_1 to avoid the dummy variable trap\n",
    "#one dummy must be treated as a baseline and removed since it will be collinear with the sum of the others \n",
    "X = df[df.columns[1:-1]] #select features \n",
    "Y = df['admit'] #select labels \n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X,Y,random_state=2) #create test and train sets \n",
    "\n",
    "### L1 ###\n",
    "model_L1 = linear_model.LogisticRegression(penalty='l1')\n",
    "model_L1.fit(train_X, train_Y)\n",
    "    \n",
    "print 'penalty: ', model_L1.penalty\n",
    "print 'accuracy', model_L1.score(test_X, test_Y) #remember to score on testing set! \n",
    "print 'weights: ', model_L1.coef_\n",
    "print \n",
    "\n",
    "### L2 ###\n",
    "model_L2 = linear_model.LogisticRegression(penalty='l2')\n",
    "model_L2.fit(train_X, train_Y)\n",
    "    \n",
    "print 'penalty: ', model_L2.penalty\n",
    "print 'accuracy', model_L2.score(test_X, test_Y)\n",
    "print 'weights: ', model_L2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning the Regularization Strength \n",
    "We can also change the regularization strength hyperparameter, λ. But of course, statisticians could not make it that easy. Sklearn replaces λ with the variable C, which is actually the inverese of the regularization strength. The way to interpret this is that C must be a postive float, and the regularization is strongest at values near 0, and weaker as you grow toward infiniti. Despite the underlying math, we tune C exactly as we would λ. \n",
    "\n",
    "In this example I loop over several different values of C and print out the accuracy results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regularization strength:  1000.0\n",
      "accuracy 0.69\n",
      "regularization strength:  100.0\n",
      "accuracy 0.69\n",
      "regularization strength:  10.0\n",
      "accuracy 0.69\n",
      "regularization strength:  1.0\n",
      "accuracy 0.65\n",
      "regularization strength:  0.1\n",
      "accuracy 0.63\n",
      "regularization strength:  0.01\n",
      "accuracy 0.63\n",
      "regularization strength:  0.001\n",
      "accuracy 0.63\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# create array of magnitudes of 10^-4 to 10^4\n",
    "strength = np.linspace(-3,3, 7)\n",
    "strength = .1**strength\n",
    "\n",
    "c = [] #log values\n",
    "a = []\n",
    "for reg_stregth in strength: #iterate over hyperparams \n",
    "    model = linear_model.LogisticRegression(penalty='l2', C=reg_stregth) #set C to value being iterated on \n",
    "    model.fit(train_X, train_Y)\n",
    "    \n",
    "    c.append(model.C) #log values\n",
    "    a.append(model.score(test_X, test_Y))\n",
    "    print 'regularization strength: ', model.C\n",
    "    print 'accuracy', model.score(test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like, for this model, regularization was not needed. The weaker regularization strengths (larger values of C) seem to improve the model. We can clearly see the effect of the strength from values 0.1-10. \n",
    "\n",
    "Below is a way to visualize the accuracy changes as a function of regularization strength. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmsAAAFECAYAAAB4XnmaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XecVPW9//HXmwWkgwhYKAICGntZAY16sWAwJjHVQtSY\nRIkm9uQm5t60m5tfcm8SW2ILotFo1JtYojGJggU1KsKCiBSpIk2lKFXa7n5+f8whGTfs7gAze2Zn\n3s/HYx4758z3nPOe7w6zH76nKSIwMzMzs+LUIu0AZmZmZlY/F2tmZmZmRczFmpmZmVkRc7FmZmZm\nVsRcrJmZmZkVMRdrZmZmZkXMxZqZmZlZEXOxZmZmZlbEXKyZmZmZFbGWaQfIp27dukXfvn3TjmFm\nZmbWqMmTJ6+MiO6NtSupYq1v375UVVWlHcPMzMysUZLeyqWdd4OamZmZFTEXa2ZmZmZFzMWamZmZ\nWRFzsWZmZmZWxFysmZmZmRUxF2tmZmZmRczFmpmZmVkRK2ixJmmEpNmS5km6pp42wyRNlTRD0nNZ\n86+QND2Zf2Uhc5qZmZkVq4JdFFdSBXAzMBxYAkyS9FhEzMxq0wW4BRgREYsk9UjmHwxcBAwGtgBP\nSHo8IuYVKq+ZmZlZMSrkHQwGA/MiYgGApAeAM4CZWW1GAg9HxCKAiFiezP8I8EpEfJAs+xzwWeDn\nBcxrZmYFtnFLDfNXrE87hlmjDu7ZOe0I/1DIYq0nsDhregkwpE6bQUArSeOBjsCNEfE7YDrw/yTt\nAWwEPg74PlJmZs3c5Q+8yriZ76Ydw6xBbVq14I3/Pi3tGP+Q9r1BWwJHAScDbYGXJU2IiFmS/hcY\nC2wApgI121uBpFHAKIA+ffo0SWgzM9txry56n3Ez3+W8oftywqBG711tlpqKIjv9spDF2lKgd9Z0\nr2RetiXAqojYAGyQ9DxwGDAnIu4A7gCQ9NOk7b+IiNHAaIDKysrI6zswM7O8uW7cHLq2b801px1A\n+93SHiswaz4KWTtOAgZK6iepNXA28FidNo8Cx0lqKakdmd2kswCyTjboQ+Z4tfsKmNXMzApo4pvv\n8cLclVzyb/u5UDPbQQX7FxMR1ZIuBZ4EKoA7I2KGpIuT129Ldnc+AUwDaoExETE9WcVDyTFrW4Fv\nRMTqQmU1M7PCiQh+OXY23TvuxrlD9007jlmzU9D/3kTEX4G/1pl3W53pXwC/2M6yxxcym5mZNY0X\n561i4pvv8aNPHkjb1hVpxzFrdorsEDozMyslEcG142azT+c2nDPEJ4GZ7QwXa2ZmVjDjZ6/g1UWr\nufSkgezW0qNqZjvDxZqZmRXEtlG1Pl3b8YXKXmnHMWu2XKyZmVlBPDnjXaYvXcvlJw+kVbFduMqs\nGfG/HjMzy7va2uD6cXPo3609nz58n7TjmDVrLtbMzCzvHn/9bWa/u44rhw+ipUfVzHaJ/wWZmVle\nVdfUcsNTc9h/z4584pC9045j1uy5WDMzs7z609RlLFixgauGD6JFC6Udx6zZc7FmZmZ5s7Wmlhuf\nnsPBPTvxsYP2TDuOWUlwsWZmZnnzx6olLH5vI1cPH4TkUTWzfHCxZmZmebG5uoabnpnLEX26cOL+\nPdKOY1YyXKyZmVlePDBxMcvWbOKbw/f3qJpZHrlYMzOzXbZxSw03PTuPwf268tEBe6Qdx6ykuFgz\nM7Nddu+Et1ixbjPf9LFqZnnnYs3MzHbJ+s3V3PrcfI4f2I0h/T2qZpZvLtbMzGyX3P3SQt7bsIWr\nhw9KO4pZSXKxZmZmO23Nxq385rn5nHxAD47os3vaccxKkos1MzPbaXf8/U3WbqrmKo+qmRWMizUz\nM9sp72/Ywp1/f5PTDt6Lg3t2TjuOWclysWZmZjtl9AsL2LDFo2pmheZizczMdtiKdZu568WFfOqw\nfRi0Z8e045iVNBdrZma2w257bj6bq2u44uSBaUcxK3ku1szMbIe8s2YT90x4i88e2Yv+3TukHces\n5LlYMzOzHXLzs/OorQ2Pqpk1ERdrZmaWsyXvf8ADkxZx5tG96d21XdpxzMqCizUzM8vZr5+ehyQu\nO2lA2lHMyoaLNTMzy8nClRt4cMoSRg7uw96d26Ydx6xsuFgzM7Oc3Pj0XFpViK+fuF/aUczKios1\nMzNr1Lzl6/jT1KV86Zi+9OjYJu04ZmXFxZqZmTXq+qfm0q5VBV/7N4+qmTU1F2tmZtagmcvW8pdp\nb/Plj/aja/vWaccxKzsu1szMrEHXPzWHjm1actHx/dOOYlaWClqsSRohabakeZKuqafNMElTJc2Q\n9FzW/KuSedMl3S/JB0mYmTWxaUtWM27mu1x0fH86t2uVdhyzslSwYk1SBXAzcBpwIHCOpAPrtOkC\n3AJ8KiIOAr6QzO8JXA5URsTBQAVwdqGympnZ9l07dg67t2vFlz/aN+0oZmWrkCNrg4F5EbEgIrYA\nDwBn1GkzEng4IhYBRMTyrNdaAm0ltQTaAcsKmNXMzOqoWvgez81Zwdf+bT86tvGomllaClms9QQW\nZ00vSeZlGwTsLmm8pMmSzgeIiKXAL4FFwNvAmogYW8CsZmZWx7Vj59CtQ2vOP2bftKOYlbW0TzBo\nCRwFnA58DPi+pEGSdiczCtcP2AdoL+nc7a1A0ihJVZKqVqxY0VS5zcxK2kvzV/LyglV8fdgA2rVu\nmXYcs7JWyGJtKdA7a7pXMi/bEuDJiNgQESuB54HDgFOANyNiRURsBR4Gjt3eRiJidERURkRl9+7d\n8/4mzMzKTURw3dg57NWpDSOH9Ek7jlnZK2SxNgkYKKmfpNZkThB4rE6bR4HjJLWU1A4YAswis/tz\nqKR2kgScnMw3M7MCe27OCqreep9LTxpAm1YVaccxK3sFG9uOiGpJlwJPkjmb886ImCHp4uT12yJi\nlqQngGlALTAmIqYDSHoQmAJUA68CowuV1czMMiKC68bNodfubTmzsnfjC5hZwSki0s6QN5WVlVFV\nVZV2DDOzZmvsjHcYdc9kfv65QznzaBdrZoUkaXJEVDbWLu0TDMzMrEjU1mZG1fru0Y7PHln35H0z\nS4uLNTMzA+Bv09/hjXfWceUpg2hZ4T8PZsXC/xrNzIya2uD6p+YwsEcHPnnYPmnHMbMsLtbMzIzH\nXlvKvOXruWr4ICpaKO04ZpbFxZqZWZnbWlPLDU/N5SN7d2LEQXulHcfM6nCxZmZW5h6esoS3Vn3A\nN4cPooVH1cyKjos1M7Mytrm6hl89PY/Denfh5I/0SDuOmW2HizUzszL2h0mLWbp6I98cPojMDWPM\nrNi4WDMzK1ObttZw07PzOLrv7hw/sFvaccysHi7WzMzK1O9fWcS7azdz9fD9PapmVsRcrJmZlaEP\ntlRz6/h5fHTAHhyz3x5pxzGzBhTsRu5mZla87n7pLVau38Jvhu+fdhQza4RH1szMysy6TVv5zfPz\nGbZ/d47ad/e045hZI1ysmZmVmTv/vpDVH2zlmx5VM2sWXKyZmZWR1R9sYcwLCzj1wD05pFfntOOY\nWQ5crJmZlZHbX1jA+i3VXH3qoLSjmFmOXKyZmZWJVes389sXF3L6IXtzwF6d0o5jZjlysWZmViZu\ne24+m7bWcOUpHlUza05crJmZlYHlazfxu5ff4tNH9GRAjw5pxzGzHeBizcysDNwyfj7VtcEVJw9M\nO4qZ7SAXa2ZmJW7p6o3c98oizqzsxb57tE87jpntIBdrZmYl7qZn5gFw6UkeVTNrjlysmZmVsEWr\nPuCPVYs5e3BvenZpm3YcM9sJLtbMzErYjU/PpaKF+MaJA9KOYmY7ycWamVmJmr9iPY+8uoTzhu7L\nnp3apB3HzHaSizUzsxJ1w1NzadOqgouH7Zd2FDPbBS7WzMxK0Ox31vH4tGVccGxfunXYLe04ZrYL\nXKyZmZWg68fNoUPrlow6oX/aUcxsF7lYMzMrMdOXruGJGe/w1eP70aVd67TjmNkucrFmZlZirhs3\nh85tW/GV4/qlHcXM8sDFmplZCZn81vs888ZyRp3Qn05tWqUdx8zyIOdiTdInJY2XNEHS1wsZyszM\nds714+awR/vWXHBs37SjmFme1FusSTq8zqzzgBOBY4FLclm5pBGSZkuaJ+maetoMkzRV0gxJzyXz\n9k/mbXuslXRlbm/JzKw8TViwir/PW8klw/aj/W4t045jZnnS0L/mSyS1AL4fEe8Ai4HvAbXAssZW\nLKkCuBkYDiwBJkl6LCJmZrXpAtwCjIiIRZJ6AETEbODwrPUsBR7ZifdnZlYWIoLrxs6hR8fdOHfo\nvmnHMbM8qrdYi4ivSToM+I2kycAPgGOAdsAvc1j3YGBeRCwAkPQAcAYwM6vNSODhiFiUbHP5dtZz\nMjA/It7KYZtmZmXp7/NWMnHhe/z4jINo06oi7ThmlkcNHrMWEa9FxBnAq8CjwD4R8VhEbM5h3T3J\njMZtsySZl20QsHtyLNxkSedvZz1nA/fnsD0zs7IUEVw7dg77dG7DWUf3TjuOmeVZQ8esXSzpJUkv\nAe2BEUAXSU9KOiFP228JHAWcDnwM+L6kQVkZWgOfAv7YQM5RkqokVa1YsSJPsczMmo9n3ljO1MWr\nufzkgezW0qNqZqWmoZG1r0fEsWROKvj3iKiOiF+RGen6dA7rXgpk/xevVzIv2xLgyYjYEBErgeeB\nw7JePw2YEhHv1reRiBgdEZURUdm9e/ccYpmZlY7a2uC6cXPo07UdnzuqV9pxzKwAGirWlkr6D+D7\nwBvbZkbE+xFxdQ7rngQMlNQvGSE7G3isTptHgeMktZTUDhgCzMp6/Ry8C9TMrF5PzniHGcvWcuUp\nA2lV4UtnmpWihs4GPYPMrsmtwA93dMURUS3pUuBJoAK4MyJmSLo4ef22iJgl6QlgGpmzTMdExHQA\nSe3JnEn6tR3dtplZOaipDa5/ag77dW/PGYfXPSTYzEpFQ2eDbgH+vCsrj4i/An+tM++2OtO/AH6x\nnWU3AHvsyvbNzErZ49OWMefd9fz6nCOoaKG045hZgXjM3MysGaquqeWGp+ZywF4dOf2QvdOOY2YF\n5GLNzKwZeuTVpby5cgNXDR9EC4+qmZW0Ros1SddKOqgpwpiZWeO2VNdy49NzOaRnZ049cM+045hZ\ngeUysjYLGC3pleTaa50LHcrMzOr3x8mLWfL+Rq4+dRCSR9XMSl2jxVpEjImIjwLnA32BaZLuk3Ri\nocOZmdmHbdpaw03PzOPIPl0YNsjXljQrBzkds5bcTP2A5LESeA24Ornfp5mZNZH7Jy7i7TWb+Nap\n+3tUzaxMNHSdNQAkXQ98AngG+GlETExe+l9JswsZzszM/mnjlhpufnY+Q/t35dgB3dKOY2ZNpNFi\njcwFa7+XXPesrsF5zmNmZvX43csLWbl+M7eee2TaUcysCeWyG3Q1WUWdpC6SPg0QEWsKFczMzP5p\n/eZqbntuPicM6s7RfbumHcfMmlAuxdoPs4uyiFjNTtx+yszMdt5dL77J+x9s5erhg9KOYmZNLJdi\nbXttctl9amZmebBm41ZGP7+AUz6yJ4f37pJ2HDNrYrkUa1WSrpO0X/K4Dphc6GBmZpZxxwsLWLup\n2qNqZmUql2LtMmAL8H/JYzPwjUKGMjOzjPc2bOHOFxfy8UP24sB9OqUdx8xS0OjuzOQs0GuaIIuZ\nmdXxm+fns2FLNVed4lE1s3KVy3XWugPfBg4C2mybHxEnFTCXmVnZW75uE3e/tJAzDtuHgXt2TDuO\nmaUkl92gvwfeAPoB/wUsBCYVMJOZmQG3jp/P1prgCo+qmZW1XIq1PSLiDmBrRDwXEV8BPKpmZlZA\nb6/ZyO9fWcTnjuxJv27t045jZinK5RIcW5Ofb0s6HVgG+IqMZmYFdPOz84gILjtpYNpRzCxluRRr\nP5HUGfgm8GugE3BVQVOZmZWxxe99wP9NWsxZR/emd9d2accxs5Q1WKxJqgAGRsTjwBrgxCZJZWZW\nxn79zFwkcemJHlUzs0aOWYuIGuCcJspiZlb23ly5gYemLOXcIfuyV+c2jS9gZiUvl92gL0q6icwF\ncTdsmxkRUwqWysysTN341BxaV7TgkmH7pR3FzIpELsXa4cnPH2fNC3xGqJlZXs19dx2PvraMUSf0\np3vH3dKOY2ZFIpc7GPg4NTOzJnD9U3No37olF5/gUTUz+6dc7mDwg+3Nj4gfb2++mZntuBnL1vDX\n19/h8pMGsHv71mnHMbMikstu0A1Zz9sAnwBmFSaOmVl5un7cXDq1aclXj++fdhQzKzK57Aa9Nnta\n0i+BJwuWyMyszExdvJqnZr3Lt04dROe2rdKOY2ZFJpfbTdXVDuiV7yBmZuXqunFz2L1dKy74aL+0\no5hZEcrlmLXXyZz9CVABdOfDZ4aamdlOmrTwPZ6fs4L/+PgBdNgtlyNTzKzc5PLN8Ims59XAuxFR\nXaA8ZmZl5dqxs+necTfOG9o37ShmVqRy2Q26N/BeRLwVEUuBtpKGFDiXmVnJe2neSiYseI+vD9uP\ntq0r0o5jZkUql2LtVmB91vSGZJ6Zme2kiOCXY2ezd+c2nDO4T9pxzKyI5VKsKSK2HbNGRNSS2+5T\nMzOrx/g5K5iyaDWXnjSANq08qmZm9culWFsg6XJJrZLHFcCCXFYuaYSk2ZLmSbqmnjbDJE2VNEPS\nc1nzu0h6UNIbkmZJOia3t2RmVtwiguvGzqF317Z84ajeaccxsyKXS7F2MXAssBRYAgwBRjW2kKQK\n4GbgNOBA4BxJB9Zp0wW4BfhURBwEfCHr5RuBJyLiAOAwfCFeMysRY2e+y+tL13D5SQNp3XJnrqBk\nZuUkl4viLgfO3ol1DwbmRcQCAEkPAGcAM7PajAQejohFWdtCUmfgBOCCZP4WYMtOZDAzKyq1tcH1\n4+bQv1t7PnNEz7TjmFkz0Oh/6STdnYyAbZveXdKdOay7J7A4a3pJMi/bIGB3SeMlTZZ0fjK/H7AC\n+K2kVyWNkdS+nnyjJFVJqlqxYkUOsczM0vOX19/mjXfWccUpA2lZ4VE1M2tcLt8Uh0bE6m0TEfE+\ncESett8SOAo4HfgY8H1Jg5L5RwK3RsQRZM5A3e4xbxExOiIqI6Kye/fueYplZpZ/NbXBDU/NYdCe\nHfjkofukHcfMmolcirUWknbfNiGpK7mdDboUyD5ytlcyL9sS4MmI2BARK4HnyRyftgRYEhGvJO0e\nJFO8mZk1W49OXcr8FRu4evggWrRQ2nHMrJnIpVi7FnhZ0n9L+gnwEvDzHJabBAyU1E9SazLHvT1W\np82jwHGSWkpqR+bkhVkR8Q6wWNL+SbuT+fCxbmZmzcrWmlpueGouB+3TiY8dtFfaccysGcnlBIPf\nSZoMnJjM+mxENFo4RUS1pEuBJ8ncU/TOiJgh6eLk9dsiYpakJ4BpQC0wJiKmJ6u4DPh9UugtAL68\no2/OzKxYPDR5CYve+4A7vlSJ5FE1M8udsq5323BDqQfQZtv0tjM4i0llZWVUVVWlHcPM7EM2V9dw\n4i/G06NTGx75+rEu1swMAEmTI6KysXa5nA36KUlzgTeB54CFwN92OaGZWZn4v0mLWbZmE988dZAL\nNTPbYbkcs/bfwFBgTkT0I3P82ISCpjIzKxGbttZw0zPzGNyvK8cN6JZ2HDNrhnIp1rZGxCoyZ4W2\niIhngUaH7MzMDO6d8BbL123mm8M9qmZmOyeXS3CsltSBzGU1fi9pOZnrnpmZWQM2bK7m1vHzOW5A\nN4b03yPtOGbWTOUysnYG8AFwFfAEMB/4ZCFDmZmVgrteWsiqDVu4+tRBaUcxs2Ysl0t3bBtFqwXu\nLmwcM7PSsHbTVkY/v4CTDujBkX12b3wBM7N6+MZ0ZmYFcOff32TNxq1cPdyjama2a1ysmZnl2eoP\ntnDHC28y4qC9OLhn57TjmFkz52LNzCzPRj+/gPVbqrnKo2pmlgeNHrMm6XWg7m0O1gBVwE+Sy3qY\nmRmwcv1mfvviQj556D7sv1fHtOOYWQnI5dIdfwNqgPuS6bOBdsA7wF34zFAzs3+4bfx8NlfXcMUp\nA9OOYmYlIpdi7ZSIODJr+nVJUyLiSEnnFiqYmVlz8+7aTdwz4S0+c0Qv9uveIe04ZlYicjlmrULS\n4G0Tko4GKpLJ6oKkMjNrhm5+dh41tcEVJ3tUzczyJ5eRtQuBO5O7GAhYC1woqT3ws0KGMzNrLpau\n3sgDExfzhcre9NmjXdpxzKyE5HJR3EnAIZI6J9Nrsl7+Q6GCmZk1Jzc9MxeAy04akHISMys1uZwN\nuhvwOaAv0HLbjYgj4scFTWZm1ky8tWoDf6hawnlD92WfLm3TjmNmJSaX3aCPkrlUx2Rgc2HjmJk1\nPzc+PZeWLcTXh+2XdhQzK0G5FGu9ImJEwZOYmTVD85av50+vLuXC4/vTo1ObtOOYWQnK5WzQlyQd\nUvAkZmbN0A1PzaFNqwq+dkL/tKOYWYnKZWTtOOACSW+S2Q0qICLi0IImMzMrcrPeXsvj097m0hMH\nsEeH3dKOY2YlKpdi7bSCpzAza4auHzeHjm1actHxHlUzs8Kpt1iT1Cki1gLrmjCPmVmz8PqSNYyd\n+S5XnTKIzu1apR3HzEpYQyNr9wGfIHMWaJDZ/blNAP6vpJmVrWvHzaZLu1Z85bi+aUcxsxJXb7EW\nEZ9IfvZrujhmZsVv8lvvM372Cr4z4gA6tvGompkVVqNng0p6Opd5Zmbl4rpxs+nWoTVfOnbftKOY\nWRlo6Ji1NkA7oJuk3fnnbtBOQM8myGZmVnRenr+KF+et4vufOJB2rXM5R8vMbNc09E3zNeBKYB8y\nx61tK9bWAjcVOJeZWdGJCK4bN5s9O+3GF4f0STuOmZWJho5ZuxG4UdJlEfHrJsxkZlaUXpi7kkkL\n3+e/P30wbVpVpB3HzMpELncweEdSRwBJ35P0sKQjC5zLzKyoRATXjp1Nzy5tOauyd9pxzKyM5FKs\nfT8i1kk6DjgFuAO4tbCxzMyKy9OzlvPakjVcfvIAWrfM5avTzCw/cvnGqUl+ng6Mjoi/AK0LF8nM\nrLjU1gbXjptD3z3a8dkje6Udx8zKTC7F2lJJvwHOAv4qabcclzMzKwlPzHiHWW+v5YpTBtKqwl9/\nZta0cvnWORN4EvhYRKwGugL/nsvKJY2QNFvSPEnX1NNmmKSpkmZIei5r/kJJryevVeWyPTOzfKup\nDa4fN4cBPTrwqcN81SIza3qNXiQoIj6QtBw4DpgLVCc/GySpArgZGA4sASZJeiwiZma16QLcAoyI\niEWSetRZzYkRsTLnd2Nmlmd/fm0Zc5ev5+aRR1LRQo0vYGaWZ7ncweCHwHeA7yazWgH35rDuwcC8\niFgQEVuAB4Az6rQZCTwcEYsAImJ5rsHNzAptS3UtNz49lwP26shpB++VdhwzK1O57Ab9DPApYANA\nRCwDOuawXE9gcdb0Ev71zgeDgN0ljZc0WdL5Wa8F8FQyf1R9G5E0SlKVpKoVK1bkEMvMrHGbq2u4\n5N7JvLlyA98ZcQAtPKpmZinJ5V4pWyIiJAWApPZ53v5RwMlAW+BlSRMiYg5wXEQsTXaNjpP0RkQ8\nX3cFETEaGA1QWVkZecxmZmVq09YaRt0zmefnrOAnnz6YEw+oe4SGmVnTyWVk7Q/J2aBdJF0EPAWM\nyWG5pUD2lSN7JfOyLQGejIgNybFpzwOHAUTE0uTncuARMrtVzcwK6oMt1Xzlrkm8MHcFP//coZw7\n1DdrN7N0NVqsRcQvgQeBh4D9gR9ExK9yWPckYKCkfpJaA2cDj9Vp8yhwnKSWktoBQ4BZktpn3TWh\nPXAqMD3XN2VmtjPWb67mgjsnMWHBKq478zDOPNp3KjCz9DW6G1TS/0bEd4Bx25lXr4iolnQpmct+\nVAB3RsQMSRcnr98WEbMkPQFMA2qBMRExXVJ/4BFJ2zLeFxFP7OR7NDNr1NpNW7ngzom8tmQNN559\nBJ88bJ+0I5mZAaCIhg/zkjQlIo6sM29aRBxa0GQ7obKyMqqqfEk2M9sxaz7Yynl3vsKst9fy63OO\nZITP/DSzJiBpckRUNtau3pE1SZcAXwf6S5qW9VJH4MVdj2hmlr73Nmzh3DGvMG/5em479yhO/sie\naUcyM/uQhnaD3gf8DfgZkH33gXUR8V5BU5mZNYEV6zZz7phXWLhqA7d/qZJ/G9Q97UhmZv+i3mIt\nItYAa4Bzmi6OmVnTeHftJkbePoFlqzfx2wuO5tgB3dKOZGa2XblcZ83MrKQsW72RkbdPYMW6zdz9\nlcEM7tc17UhmZvVysWZmZWXxex8wcswEVm/Yyu++OoSj9t097UhmZg1ysWZmZeOtVRsYefsrrNu0\nlXsvHMJhvbukHcnMrFEu1sysLMxfsZ6Rt09gS3Ut948aykH7dE47kplZTlysmVnJm/PuOkbe/goQ\nPDDqGPbfq2PakczMcuZizcxK2sxlazn3jldo2ULcd9ExDOjRIe1IZmY7xMWamZWs6UvXcO4dr9C2\nVQX3XTSUft3apx3JzGyHuVgzs5L06qL3Of/OiXRq04oHRg2ld9d2aUcyM9spLtbMrORMWvgeX/7t\nJPbo0Jr7LhpKzy5t045kZrbTXKyZWUl5ef4qvnr3JPbq3Ib7LhzKXp3bpB3JzGyXtEg7gJlZvrww\ndwVfvmsiPbu05YFRLtTMrDR4ZM3MSsKzbyzna/dOpn+39vz+wiHs0WG3tCOZmeWFizUza/bGzniH\nb9w3hf336sg9XxnC7u1bpx3JzCxvXKyZWbP2l2lvc8UDr3Jwz87c/ZXBdG7bKu1IZmZ55WPWzKzZ\nenTqUi67fwpH9OnCPV91oWZmpckja2bWLD04eQn//uBrDOnXlTu+dDTtd/PXmZmVJn+7mVmzc//E\nRfzHI69z3IBujD6vkratK9KOZGZWMN4NambNyu9eXsh3H36dYYO6c/v5LtTMrPR5ZM3Mmo0xLyzg\nJ3+ZxfAD9+SmkUewW0sXamZW+lysmVmzcMv4efz8idmcfsje3HD24bSq8I4BMysPLtbMrKhFBL96\neh7XPzWHMw7fh2u/cBgtXaiZWRlxsWZmRSsi+OXY2dz87Hw+f1Qv/vdzh1LRQmnHMjNrUi7WzKwo\nRQQ//euyQgcsAAAUNElEQVQsbn/hTc4Z3If/9+mDaeFCzczKkIs1Mys6EcF//Xkmd720kC8dsy8/\n+tRBSC7UzKw8uVgzs6JSWxt879Hp3PfKIi48rh//efpHXKiZWVlzsWZmRaOmNrjmoWn8cfISvj5s\nP/79Y/u7UDOzsudizcyKQnVNLd/642v8aeoyrjxlIFecPNCFmpkZLtbMrAhsranlygem8pfX3+bf\nP7Y/3zhxQNqRzMyKhos1M0vV5uoaLrvvVcbOfJf//PhHuOiE/mlHMjMrKgW9sqSkEZJmS5on6Zp6\n2gyTNFXSDEnP1XmtQtKrkh4vZE4zS8emrTVccu8Uxs58lx998kAXamZm21GwkTVJFcDNwHBgCTBJ\n0mMRMTOrTRfgFmBERCyS1KPOaq4AZgGdCpXTzNKxcUsNo+6p4oW5K/npZw5h5JA+aUcyMytKhRxZ\nGwzMi4gFEbEFeAA4o06bkcDDEbEIICKWb3tBUi/gdGBMATOaWQo+2FLNV+6axN/nreTnnz/UhZqZ\nWQMKWaz1BBZnTS9J5mUbBOwuabykyZLOz3rtBuDbQG1DG5E0SlKVpKoVK1bkI7eZFdC6TVv50p0T\neeXNVVx/5uGcWdk77UhmZkUt7RMMWgJHAScDbYGXJU0gU8Qtj4jJkoY1tIKIGA2MBqisrIzCxjWz\nXbFmY6ZQe33pGn51zhF84tB90o5kZlb0ClmsLQWy/8vcK5mXbQmwKiI2ABskPQ8cBhwJfErSx4E2\nQCdJ90bEuQXMa2YFtPqDLZx3x0TeeGctt3zxSD520F5pRzIzaxYKuRt0EjBQUj9JrYGzgcfqtHkU\nOE5SS0ntgCHArIj4bkT0ioi+yXLPuFAza75Wrd/MObe/wux31/Gb845yoWZmtgMKNrIWEdWSLgWe\nBCqAOyNihqSLk9dvi4hZkp4AppE5Nm1MREwvVCYza3rL123i3DGv8NaqDxhzfiUnDOqediQzs2ZF\nEaVzmFdlZWVUVVWlHcPMEu+s2cTIMRN4e/Um7rigkmP365Z2JDOzoiFpckRUNtYu7RMMzKxELV29\nkZG3T2Dlus3c/ZXBDO7XNe1IZmbNkos1M8u7xe99wDm3T2DNxq3cc+EQjuyze9qRzMyaLRdrZpZX\nC1duYOTtE9iwpYb7LhzKIb06px3JzKxZc7FmZnkzb/l6Rt4+gera4P6LhnLgPr5TnJnZrnKxZmZ5\nMfuddXxxzARA3H/RUPbfq2PakczMSkIhr7NmZmVixrI1nD36ZVpIPDDKhZqZWT55ZM3Mdsm0Jas5\n746JtG9dwX0XDaVvt/ZpRzIzKyku1sxsp01Z9D5fumMindu14v6LhtK7a7u0I5mZlRwXa2a2Uya+\n+R5f/u1EunXcjfsvGso+XdqmHcnMrCS5WDOzHfbSvJV89e4q9u7ShvsvGsqendqkHcnMrGT5BAMz\n2yHPz1nBl++aRO+ubfm/Uce4UDMzKzCPrJlZzp55410uvmcK+/XowL1fHcweHXZLO5KZWclzsWZm\nOXli+jtcdv8UDtirE/d8dTBd2rVOO5KZWVnwblAza9Tj05bxjfumcHDPztx74RAXamZmTcgja2bW\noEdeXcI3//AaR+27O7/98mA67OavDTOzpuRvXTOr1x+qFvOdh6YxtN8e3HFBJe1a+yvDzKypeTeo\nmW3X7195i28/OI3jBnTjzguOdqFmZpYSf/ua2b+468U3+dGfZ3LSAT245YtH0qZVRdqRzMzKlos1\nM/uQ0c/P56d/fYNTD9yTm0YeSeuWHoA3M0uTizUz+4ebn53HL56czemH7s0NZx1OqwoXamZmaXOx\nZmZEBDc8NZcbn57LZ47oyS8+fygtXaiZmRUFF2tmZS4i+PmTs7l1/Hy+cFQv/udzh1LRQmnHMjOz\nhIs1szIWEfzkL7O44+9vMnJIH35yxsG0cKFmZlZUXKyZlana2uBHf57B715+iwuO7csPP3kgkgs1\nM7Ni42LNrAzV1gb/+afXuX/iYkad0J/vnnaACzUzsyLlYs2szNTUBt9+cBoPTVnCpScO4JunDnKh\nZmZWxFysmZWR6ppavvnH13h06jKuOmUQV5wyMO1IZmbWCBdrZmVia00tVzzwKn99/R2+PWJ/vj5s\nQNqRzMwsBy7WzMrA5uoaLr3vVcbNfJfvnf4RLjy+f9qRzMwsRy7WzErcpq01XHLvZJ6dvYIfn3EQ\n5x/TN+1IZma2A1ysmZWwjVtquOh3Vbw4fyU/++whnDO4T9qRzMxsB7lYMytRGzZX89W7J/HKm+/x\n888dyhcqe6cdyczMdkJBb/4naYSk2ZLmSbqmnjbDJE2VNEPSc8m8NpImSnotmf9fhcxpVmrWbdrK\nl+6cyKSF73PDWYe7UDMza8YKNrImqQK4GRgOLAEmSXosImZmtekC3AKMiIhFknokL20GToqI9ZJa\nAX+X9LeImFCovGalYs3GrZx/50RmLF3Dr885go8fsnfakczMbBcUcjfoYGBeRCwAkPQAcAYwM6vN\nSODhiFgEEBHLk58BrE/atEoeUcCsOVm5fjPVNanHMKvXxq01XHb/FGa/s45bvngkpx60V9qRzMxs\nFxWyWOsJLM6aXgIMqdNmENBK0nigI3BjRPwO/jEyNxkYANwcEa8UMGtOzrtjIrPeXpt2DLMGtW7Z\ngtHnVXLiAT0ab2xmZkUv7RMMWgJHAScDbYGXJU2IiDkRUQMcnuwqfUTSwRExve4KJI0CRgH06VPY\nM90uP2kAqzduLeg2zHbVYb26cOA+ndKOYWZmeVLIYm0pkH1Uc69kXrYlwKqI2ABskPQ8cBgwZ1uD\niFgt6VlgBPAvxVpEjAZGA1RWVhZ0H+VpPvbHzMzMmlghzwadBAyU1E9Sa+Bs4LE6bR4FjpPUUlI7\nMrtJZ0nqnoyoIaktmZMU3ihgVjMzM7OiVLCRtYiolnQp8CRQAdwZETMkXZy8fltEzJL0BDANqAXG\nRMR0SYcCdyfHrbUA/hARjxcqq5mZmVmxUubEy9JQWVkZVVVVaccwMzMza5SkyRFR2Vi7gl4U18zM\nzMx2jYs1MzMzsyLmYs3MzMysiLlYMzMzMytiLtbMzMzMipiLNTMzM7Mi5mLNzMzMrIiV1HXWJK0A\n3trOS52BNTmuprG23YCVOxhtR+1I3rS2k+uyxdCfueRIexv+jOZ/O/n6jELp9Gk5fUZzyZH2NvwZ\nze92muNndGBEdG60VUSU/AMYna+2QFUx5U1rO7kuWwz92VR92hT9WSx9Wk6f0VLq03L6jJZSn5bT\nZ3RXtlPKn9Fy2Q365wK1LZSmyrAr28l12WLoT2iaHE3Rn7u6nXzxZzT//BnNv1Lp03Lqz13ZTsl+\nRktqN2hTkFQVOdwawnLj/sw/92n+uU/zy/2Zf+7T/Cq2/iyXkbV8Gp12gBLj/sw/92n+uU/zy/2Z\nf+7T/Cqq/vTImpmZmVkR88iamZmZWRFzsWZmZmZWxFysmZmZmRUxF2t5JOkjkm6T9KCkS9LO09xJ\n+rSk2yX9n6RT085TCiT1l3SHpAfTztJcSWov6e7ks/nFtPOUAn8u88vfnfmX9t93F2sJSXdKWi5p\nep35IyTNljRP0jUNrSMiZkXExcCZwEcLmbfY5ak//xQRFwEXA2cVMm9zkKc+XRARXy1s0uZnB/v2\ns8CDyWfzU00etpnYkT7157JxO9if/u7MwQ72aap/312s/dNdwIjsGZIqgJuB04ADgXMkHSjpEEmP\n13n0SJb5FPAX4K9NG7/o3EUe+jPxvWS5cncX+etT+7C7yLFvgV7A4qRZTRNmbG7uIvc+tcbdxY73\np787G3YXO9Cnaf59b9nUGyxWEfG8pL51Zg8G5kXEAgBJDwBnRMTPgE/Us57HgMck/QW4r3CJi1s+\n+lOSgP8B/hYRUwqbuPjl6zNq/2pH+hZYQqZgm4r/w1uvHezTmU2brvnZkf6UNAt/dzZqRz+jaf59\n9xdNw3ryz/9BQ+ZLumd9jSUNk/QrSb/BI2vbs0P9CVwGnAJ8XtLFhQzWjO3oZ3QPSbcBR0j6bqHD\nNXP19e3DwOck3Urx3LKmudhun/pzudPq+4z6u3Pn1fcZTfXvu0fW8igixgPjU45RMiLiV8Cv0s5R\nSiJiFZnjWGwnRcQG4Mtp5ygl/lzml7878y/tv+8eWWvYUqB31nSvZJ7tHPdn/rlPC8d9m3/u0/xy\nf+ZfUfapi7WGTQIGSuonqTVwNvBYypmaM/dn/rlPC8d9m3/u0/xyf+ZfUfapi7WEpPuBl4H9JS2R\n9NWIqAYuBZ4EZgF/iIgZaeZsLtyf+ec+LRz3bf65T/PL/Zl/zalPfSN3MzMzsyLmkTUzMzOzIuZi\nzczMzKyIuVgzMzMzK2Iu1szMzMyKmIs1MzMzsyLmYs3MzMysiLlYMytxktbvxDJ/ldRlJ5a7UlK7\nXV1Pjts6XNLHC7Hu7WxrmKRjs6bvkvT5RpbpK2l64dM1D5L+I0/r+ZakNyRNlTRJ0vn5WK9ZMXOx\nZlZElJHav8tt24+Ij0fE6p1YxZXAP4q1XVhPLg4HtlusScr3fY+HAcc21ihN+XjPkirykaUeO1ys\n1c2T3JR8ODA4Ig4HTgaUn3hmxcvFmlnKkhGY2ZJ+B0wHeks6VdLLkqZI+qOkDknbjyejCpMl/UrS\n48n8H0n6VtY6p0vqW2c7HSQ9nazzdUlnNLD9hZK6Sbo4GcGYKulNSc8my9wqqUrSDEn/lcy7HNgH\neDar3UJJ3ZLnVye5pku6MmvbsyTdnqxrrKS22+mjLyTLvSbp+eQ2MD8GzkqynZX0wT2SXgTukVQh\n6RfJ6Ms0SV9L1jVM0nhJDyZ9+XtJqq9/k368GLgq2dbxSawTJL0kaUEDo2wVdd+bpP0kTcl6bwO3\nTSf99fPk9zNR0oBkfndJDyXvZZKkj2b93rPf8wWSHk3e31xJP8zazp+S9zVD0qis+eslXSvpNeAY\nST9ItjFd0uisvhkv6frk9z5L0tGSHk6285Os9Z2bZJ8q6TfJ7+F/gLbJvN/X1257eer0538Al0TE\nWoCIWBsRd9fT92alIyL88MOPFB9AX6AWGJpMdwOeB9on098BfgC0ARYD/ZL59wOPJ89/BHwra53T\ngb7J8/XJz5ZAp6xtzCMzKvGh7SevLwS6ZU23Al4APplMd01+VgDjgUPrWW5hsq2jgNeB9kAHYAZw\nRLLtauDwpP0fgHO300evAz2T512SnxcAN2W1+REwGWibTI8Cvpc83w2oAvqRGSVbQ+YGzS3I3G7m\nuB3s37uAPybLHwjMq+f3ut33BjybNf+nwGVZ/fWfyfPzs7Z/H3Bc8rwPMKue93wB8DawB9CWzOeg\nss7vbNv8PZLpAM7Myt016/k9Wb/z8cD/Js+vAJYBeyd9uyTZ5keAPwOtkna3AOdnfw6T5w21+1Ce\nrGU6Ae+n/e/VDz/SeOR7V4GZ7Zy3ImJC8nwomQLgxWRQozWZguIAYEFEvJm0u59MQZIrAT+VdAKZ\n4qwnsOd2tr89NwLPRMSfk+kzk9GZlmT+YB8ITGtg+eOARyJiA4Ckh4Hjydwg+c2ImJq0m0ymyKnr\nReAuSX8AHm5gO49FxMbk+anAoVmjXp2BgcAWYGJELEmyTE22uZ4d698/RUQtMFPSnvW0qe+9jQG+\nLOlq4CxgcNYy92f9vD55fgpwYPJ5AOikZLS1znsGGBcRq5L39jCZvq8CLpf0maRN76QvVgE1wENZ\ny58o6dtkdmd3JVNYb/u9b7uh9evAjIh4O9nOgmSdx5EpzCclWdsCy7fTLyc30K5uHrOy52LNrDhs\nyHouMn9wz8luIOnwBpav5sOHNbTZTpsvAt2BoyJiq6SFWe02bKf9tu1eAOxL5ubGSOoHfAs4OiLe\nl3RXPdvL1eas5zVk/nB/SERcLGkIcDowWdJR9ayrbj9eFhFPZjeQNGw729yZ78LsddR33FR97+0h\n4IfAM8DkbcVVIrbzvAWZkc9N2StPCp26v7u6N3yO5D2fAhwTER9IGs8/f2ebIqImWV8bMqNclRGx\nWNKP+PDvdtv7qa3z3mrJ9KGAuyPiuzSsoXb/yPOhNxGxNtlF2j8iFjSyfrOS4mPWzIrPBOCjWccr\ntZc0CJgN9Nc/j0U7K2uZhcCRSfsjyezuq6szsDwp1E4kU4A1KCmKvkVm911tMrsTmQJhTTKidFrW\nIuuAjttZ1QvApyW1k9Qe+EwyLyeS9ouIVyLiB8AKMqM49W1rmyeBSyS1StYxKNl2fRrq38a2tUOS\noutJ4Fbgt3VePivr58vJ87HAZdsaNFK4D5fUVZlj/z5NZlSyM5ldiB9IOoDM6O32bCvMViYjdw2e\n8bodTwOfl9QjydlV0rbP2dZtv4tG2jXkZ8DNkjoly3WQzwa1MuCRNbMiExErktGs+yXtlsz+XkTM\nkfR14AlJG4BJWYs9BJwvaQbwCjBnO6v+PfBnSa+T2S32Rg5xLiWzK+zZZBSnKiIulPRqsvxiMsXA\nNqOTfMsi4sSs9zQlGYGbmMwaExGvZhVGjfmFpIFkRmSeBl4DFgHXJLsxf7adZcaQ2e04JTlIfgWZ\n4mW7ImJjA/37Z+BBZU7KuGy7K9hxvydTtI6tM393SdPIjFxtG129nEyRMo3M9/bzZE562J6JZD4P\nvYB7I6Iq+Z1fLGkWmaJ0u7u8I2K1pNvJHNP2Dh/ug0ZFxExJ3wPGKnNW81bgG8BbZD4b0yRNiYgv\nNtCuIbeSOeZxkqStyXLX7khGs+ZIEXVHzM2sWEnqEBHrk+LjZmBuRFzf2HKWm6bsX2XO3u0cEd/P\nmreQzC7IlTu5zguS5S/NS0gzKwoeWTNrXi6S9CUyJx28Cvwm5Tylpkn6V9IjwH7ASYVYv5mVFo+s\nmZmZmRUxn2BgZmZmVsRcrJmZmZkVMRdrZmZmZkXMxZqZmZlZEXOxZmZmZlbEXKyZmZmZFbH/DyUU\nsK2xr0TdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x8a93518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "fig = plt.figure(figsize=(10,5))\n",
    "ax = plt.subplot(111)\n",
    "ax.plot(c,a)\n",
    "ax.set_xscale('log')\n",
    "plt.xlabel('regularization strength hyperparameter C')\n",
    "plt.ylabel('testing accuracy %')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Regularization is a technique to optimize model fit, most commonly to prevent overfitting. It works by penalizing the weights matrix, W, based on the size of your feature coefficients. Applying the penalty has the effect of generalizing the model to new data, but sometimes lowering the training accuracy. L2 regularization, or Ridge, is the most common for preventing overfitting. L1 regularization has the possibility to remove features from the data, and is better for extremely large datasets. Regularization comes with the need to tune the λ hyperparameter, which is the strength of the penalty. \n",
    "\n",
    "In practice, regularization has the following work flow:\n",
    "\n",
    "    1) Determine if regularization should be applied. Is there a discrepancy in training and testing accuracy? \n",
    "    2) Which type to use? Is the model overfit? How big is the dataset? \n",
    "    3) Tune λ, the strength of the regularization to optimize testing accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sources: \n",
    "\n",
    "1) https://www.quora.com/What-is-regularization-in-machine-learning\n",
    "\n",
    "2) http://www.pyimagesearch.com/2016/09/19/understanding-regularization-for-image-classification-and-machine-learning/\n",
    "\n",
    "3) https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
