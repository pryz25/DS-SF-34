{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-SF-34 | 18 | Natural Language Processing | Codelong | Starter Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>> One-time setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/peterr/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#''''''\n",
    "import nltk\n",
    "nltk.download()\n",
    "#''''''\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <<< One-time setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A | Tokenization and Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "import string\n",
    "import unicodedata\n",
    "from nltk import tokenize, corpus, stem\n",
    "\n",
    "from sklearn import feature_extraction, linear_model, ensemble, model_selection, metrics, decomposition\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(document):\n",
    "    document = document.encode('utf-8')\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = tokenize.word_tokenize(document)\n",
    "\n",
    "    # Remove punctuation in tokens and then remove empty tokens\n",
    "    tokens = [token.translate(None, string.punctuation) for token in tokens]\n",
    "    tokens = [token for token in tokens if token]\n",
    "\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if not token in corpus.stopwords.words('english')]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence', 'wait', 'another', 'third']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize_text(\"This is a sentence...  Wait, here's another.  And a third!\")\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stemmer:\n",
    "    stemmer = stem.porter.PorterStemmer()\n",
    "\n",
    "    @staticmethod\n",
    "    def stem_tokens(tokens):\n",
    "        return [Stemmer.stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sentenc', 'wait', u'anoth', 'third']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = Stemmer.stem_tokens(tokens)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B | Book reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will be analyzing a partial list of the reviews for J.K. Rowling's The Casual Vacancy.  (https://www.amazon.com/dp/0316228532)  We scrapped this dataset during class 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('..', 'datasets', 'dataset-18-reviews.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-04-21</td>\n",
       "      <td>R3TUANQ2EB3ECB</td>\n",
       "      <td>MichaelMichaels</td>\n",
       "      <td>Skip it. Life is too short.</td>\n",
       "      <td>I've never read any of the Harry Potter books ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>R2DD03ZZ4218VW</td>\n",
       "      <td>Frans van Wyk</td>\n",
       "      <td>Four Stars</td>\n",
       "      <td>Excellent Read with a lot of real life values ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-04-20</td>\n",
       "      <td>R296NVKLH5QS4W</td>\n",
       "      <td>Sabina Duke</td>\n",
       "      <td>Characters</td>\n",
       "      <td>Hard to keep the characters straight</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04-05</td>\n",
       "      <td>R3MP7W8LH6VHU8</td>\n",
       "      <td>Jen Blau</td>\n",
       "      <td>GIVE IT A CHANCE!</td>\n",
       "      <td>I almost put this book down. I'm new to Rowlin...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-04-04</td>\n",
       "      <td>RZWP48RKJCXT1</td>\n",
       "      <td>Lilith Eleanor</td>\n",
       "      <td>Frighteningly good</td>\n",
       "      <td>Amazing. Rowling combines fantastic writing wi...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>RT2TE0W92SL67</td>\n",
       "      <td>Tricia K.</td>\n",
       "      <td>Seriously?  $17 bucks for a computer file???  ...</td>\n",
       "      <td>Premise sounds dull as dirt.  For $17 for a co...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R14ZGYPSP9H0Y7</td>\n",
       "      <td>Pretzel</td>\n",
       "      <td>A must read</td>\n",
       "      <td>The depth of character development and storyli...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5858</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R1913ISIDAGQ1A</td>\n",
       "      <td>Prodigy</td>\n",
       "      <td>I love it</td>\n",
       "      <td>The book was great and I will love to re-read ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5859</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R2JY771IW7RI3R</td>\n",
       "      <td>David Katz</td>\n",
       "      <td>Kendle price too expensive</td>\n",
       "      <td>I started to order the kindle edition and than...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>2012-09-27</td>\n",
       "      <td>R22B7K1DUJR6ZN</td>\n",
       "      <td>M. A. Barnett</td>\n",
       "      <td>too expensive</td>\n",
       "      <td>I would love to buy this book but it is too ex...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5861 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date              id           author  \\\n",
       "0     2017-04-21  R3TUANQ2EB3ECB  MichaelMichaels   \n",
       "1     2017-04-20  R2DD03ZZ4218VW    Frans van Wyk   \n",
       "2     2017-04-20  R296NVKLH5QS4W      Sabina Duke   \n",
       "3     2017-04-05  R3MP7W8LH6VHU8         Jen Blau   \n",
       "4     2017-04-04   RZWP48RKJCXT1   Lilith Eleanor   \n",
       "...          ...             ...              ...   \n",
       "5856  2012-09-27   RT2TE0W92SL67        Tricia K.   \n",
       "5857  2012-09-27  R14ZGYPSP9H0Y7          Pretzel   \n",
       "5858  2012-09-27  R1913ISIDAGQ1A          Prodigy   \n",
       "5859  2012-09-27  R2JY771IW7RI3R       David Katz   \n",
       "5860  2012-09-27  R22B7K1DUJR6ZN    M. A. Barnett   \n",
       "\n",
       "                                                  title  \\\n",
       "0                           Skip it. Life is too short.   \n",
       "1                                            Four Stars   \n",
       "2                                            Characters   \n",
       "3                                     GIVE IT A CHANCE!   \n",
       "4                                    Frighteningly good   \n",
       "...                                                 ...   \n",
       "5856  Seriously?  $17 bucks for a computer file???  ...   \n",
       "5857                                        A must read   \n",
       "5858                                          I love it   \n",
       "5859                         Kendle price too expensive   \n",
       "5860                                      too expensive   \n",
       "\n",
       "                                                   body  star_rating  \n",
       "0     I've never read any of the Harry Potter books ...          1.0  \n",
       "1     Excellent Read with a lot of real life values ...          4.0  \n",
       "2                  Hard to keep the characters straight          4.0  \n",
       "3     I almost put this book down. I'm new to Rowlin...          5.0  \n",
       "4     Amazing. Rowling combines fantastic writing wi...          5.0  \n",
       "...                                                 ...          ...  \n",
       "5856  Premise sounds dull as dirt.  For $17 for a co...          1.0  \n",
       "5857  The depth of character development and storyli...          5.0  \n",
       "5858  The book was great and I will love to re-read ...          5.0  \n",
       "5859  I started to order the kindle edition and than...          5.0  \n",
       "5860  I would love to buy this book but it is too ex...          1.0  \n",
       "\n",
       "[5861 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['date', 'id', 'author', 'title'],\n",
    "    axis = 1,\n",
    "    inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I've never read any of the Harry Potter books ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Excellent Read with a lot of real life values ...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hard to keep the characters straight</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I almost put this book down. I'm new to Rowlin...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amazing. Rowling combines fantastic writing wi...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5856</th>\n",
       "      <td>Premise sounds dull as dirt.  For $17 for a co...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>The depth of character development and storyli...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5858</th>\n",
       "      <td>The book was great and I will love to re-read ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5859</th>\n",
       "      <td>I started to order the kindle edition and than...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5860</th>\n",
       "      <td>I would love to buy this book but it is too ex...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5861 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body  star_rating\n",
       "0     I've never read any of the Harry Potter books ...          1.0\n",
       "1     Excellent Read with a lot of real life values ...          4.0\n",
       "2                  Hard to keep the characters straight          4.0\n",
       "3     I almost put this book down. I'm new to Rowlin...          5.0\n",
       "4     Amazing. Rowling combines fantastic writing wi...          5.0\n",
       "...                                                 ...          ...\n",
       "5856  Premise sounds dull as dirt.  For $17 for a co...          1.0\n",
       "5857  The depth of character development and storyli...          5.0\n",
       "5858  The book was great and I will love to re-read ...          5.0\n",
       "5859  I started to order the kindle edition and than...          5.0\n",
       "5860  I would love to buy this book but it is too ex...          1.0\n",
       "\n",
       "[5861 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `NaN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "body           3\n",
       "star_rating    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive, neutral, and negatives reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "#def polarity(star_rating):\n",
    "   # if star_rating <= 2.0:\n",
    "    #    star_rating = -1\n",
    "    #elif star_rating > 2.0 and < \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['polarity'] = df.star_rating.map({1: -1, 2: -1, 3: 0, 4: 1, 5: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    2711\n",
       "-1    2177\n",
       " 0     970\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ns = df.polarity.value_counts()\n",
    "ns.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for polarity in [-1, 0, 1]:\n",
    "    n = ns[polarity] - ns.min()\n",
    "    index = df[df.polarity == polarity].sample(n = n, random_state = 0).index\n",
    "    df.drop(index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    970\n",
       "-1    970\n",
       " 0    970\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.polarity.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature matrix and response vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "X = df.body\n",
    "c = df.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_c, test_c = model_selection.train_test_split(X, c, stratify = c, train_size = .6, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF and `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomTokenizer(object):\n",
    "    def __call__(self, document):\n",
    "        tokens = tokenize_text(document)\n",
    "        tokens = Stemmer.stem_tokens(tokens)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.TfidfVectorizer(tokenizer = CustomTokenizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<__main__.CustomTokenizer object at 0x1196e1450>,\n",
       "        use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['012315',\n",
       " '08',\n",
       " '1',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1012',\n",
       " '105',\n",
       " '11',\n",
       " '110',\n",
       " '12',\n",
       " '120',\n",
       " '13',\n",
       " '130',\n",
       " '132',\n",
       " '14',\n",
       " '142',\n",
       " '143',\n",
       " '149',\n",
       " '1495',\n",
       " '1499',\n",
       " '15',\n",
       " '150',\n",
       " '17',\n",
       " '170',\n",
       " '175',\n",
       " '1799',\n",
       " '18',\n",
       " '1860',\n",
       " '18th',\n",
       " '1950',\n",
       " u'1960',\n",
       " '1984',\n",
       " '19th',\n",
       " '1star',\n",
       " '2',\n",
       " '20',\n",
       " '200',\n",
       " '2012',\n",
       " '2015',\n",
       " '2016',\n",
       " '21',\n",
       " '21st',\n",
       " '23',\n",
       " '230am',\n",
       " '236',\n",
       " '24',\n",
       " '25',\n",
       " '250',\n",
       " '27',\n",
       " '28',\n",
       " '2nd',\n",
       " '3',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '31',\n",
       " '32',\n",
       " '34',\n",
       " '35',\n",
       " '355',\n",
       " '380',\n",
       " '3d',\n",
       " '3rd',\n",
       " '4',\n",
       " '40',\n",
       " '400',\n",
       " '40ish',\n",
       " '412star',\n",
       " '44',\n",
       " '45',\n",
       " '450',\n",
       " '5',\n",
       " '50',\n",
       " '500',\n",
       " '500th',\n",
       " '503',\n",
       " '505',\n",
       " '50th',\n",
       " '56',\n",
       " '57',\n",
       " '6',\n",
       " '60',\n",
       " '600',\n",
       " '6080',\n",
       " '62',\n",
       " '6th',\n",
       " '7',\n",
       " '70',\n",
       " '72',\n",
       " '75',\n",
       " '77',\n",
       " '8',\n",
       " '80',\n",
       " '800',\n",
       " '89',\n",
       " '90',\n",
       " '92',\n",
       " '93',\n",
       " '98',\n",
       " '9997',\n",
       " 'aand',\n",
       " 'aback',\n",
       " 'abandon',\n",
       " u'abil',\n",
       " 'abject',\n",
       " u'abl',\n",
       " u'abnorm',\n",
       " u'abort',\n",
       " 'abound',\n",
       " u'aboutth',\n",
       " 'abraham',\n",
       " 'abrupt',\n",
       " u'abruptli',\n",
       " u'absenc',\n",
       " u'absentmindedli',\n",
       " u'absolut',\n",
       " u'absorb',\n",
       " u'absurd',\n",
       " u'abund',\n",
       " u'abus',\n",
       " u'abut',\n",
       " u'accent',\n",
       " u'accept',\n",
       " u'access',\n",
       " u'accid',\n",
       " u'accident',\n",
       " u'accomplish',\n",
       " u'accord',\n",
       " 'account',\n",
       " u'accur',\n",
       " u'accuraci',\n",
       " u'accus',\n",
       " u'accustom',\n",
       " u'acerb',\n",
       " u'ach',\n",
       " u'achiev',\n",
       " u'acknowledg',\n",
       " u'acom',\n",
       " 'acorn',\n",
       " u'acquaint',\n",
       " u'across',\n",
       " u'act',\n",
       " u'action',\n",
       " u'actionpack',\n",
       " u'activ',\n",
       " u'activit',\n",
       " 'actor',\n",
       " u'actress',\n",
       " u'actual',\n",
       " 'acumen',\n",
       " u'acut',\n",
       " u'ad',\n",
       " u'adapt',\n",
       " 'add',\n",
       " u'addict',\n",
       " u'addit',\n",
       " u'address',\n",
       " 'adept',\n",
       " u'adeptli',\n",
       " u'adequ',\n",
       " u'adjac',\n",
       " u'adject',\n",
       " 'adjust',\n",
       " u'adloesc',\n",
       " u'administ',\n",
       " u'admir',\n",
       " 'admit',\n",
       " u'admittedli',\n",
       " u'adolesc',\n",
       " u'ador',\n",
       " 'adrian',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " u'adultthem',\n",
       " u'adut',\n",
       " u'advantag',\n",
       " u'adventur',\n",
       " u'advert',\n",
       " u'advertis',\n",
       " u'advic',\n",
       " u'advis',\n",
       " u'advoc',\n",
       " 'affair',\n",
       " u'affect',\n",
       " 'affluent',\n",
       " 'afraid',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " u'afterward',\n",
       " 'agatha',\n",
       " 'age',\n",
       " u'ageless',\n",
       " u'agenda',\n",
       " 'agent',\n",
       " 'agesa',\n",
       " u'aggress',\n",
       " u'agit',\n",
       " 'ago',\n",
       " u'agre',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aid',\n",
       " u'aim',\n",
       " u'aimless',\n",
       " u'air',\n",
       " 'airport',\n",
       " 'aka',\n",
       " 'akin',\n",
       " 'al',\n",
       " u'ala',\n",
       " 'albeit',\n",
       " 'alcohol',\n",
       " 'alert',\n",
       " u'alexand',\n",
       " u'alik',\n",
       " u'aliv',\n",
       " u'alleg',\n",
       " u'allegi',\n",
       " u'allegor',\n",
       " 'alley',\n",
       " u'alli',\n",
       " 'allnight',\n",
       " 'allot',\n",
       " u'allow',\n",
       " 'allround',\n",
       " u'alltim',\n",
       " u'allus',\n",
       " u'allveri',\n",
       " 'almost',\n",
       " u'alon',\n",
       " 'along',\n",
       " 'alot',\n",
       " u'alreadi',\n",
       " 'alright',\n",
       " 'also',\n",
       " u'altern',\n",
       " 'although',\n",
       " u'altogeth',\n",
       " 'altruism',\n",
       " u'alway',\n",
       " 'amateurish',\n",
       " u'amaz',\n",
       " u'amazingli',\n",
       " 'amazom',\n",
       " 'amazon',\n",
       " 'amazoncom',\n",
       " 'amazonon',\n",
       " u'ambigu',\n",
       " u'ambit',\n",
       " u'ambiti',\n",
       " u'ambival',\n",
       " 'america',\n",
       " 'american',\n",
       " u'ami',\n",
       " 'amidst',\n",
       " u'amiss',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " u'amus',\n",
       " u'analog',\n",
       " u'andi',\n",
       " 'andor',\n",
       " u'anecdot',\n",
       " 'aneurysm',\n",
       " u'angel',\n",
       " 'anger',\n",
       " u'angl',\n",
       " u'anglophil',\n",
       " u'angri',\n",
       " 'angst',\n",
       " 'ann',\n",
       " u'anniversari',\n",
       " u'announc',\n",
       " u'annoy',\n",
       " u'anoth',\n",
       " u'anotherth',\n",
       " u'answer',\n",
       " u'antagonist',\n",
       " u'anticip',\n",
       " u'anticlimact',\n",
       " u'anticlimat',\n",
       " u'antifield',\n",
       " u'antihero',\n",
       " u'antiheroin',\n",
       " u'antip',\n",
       " u'antithesi',\n",
       " u'anxieti',\n",
       " u'anxiou',\n",
       " u'anybodi',\n",
       " 'anyday',\n",
       " u'anymor',\n",
       " u'anyon',\n",
       " u'anyth',\n",
       " 'anytown',\n",
       " 'anyway',\n",
       " u'anywher',\n",
       " 'apart',\n",
       " u'apathi',\n",
       " u'apologet',\n",
       " u'appal',\n",
       " u'appar',\n",
       " 'appeal',\n",
       " u'appear',\n",
       " 'applaud',\n",
       " u'applaus',\n",
       " u'appli',\n",
       " u'appreci',\n",
       " u'apprehens',\n",
       " u'apprentic',\n",
       " 'approach',\n",
       " u'appropri',\n",
       " u'approv',\n",
       " u'approxim',\n",
       " 'apt',\n",
       " u'arc',\n",
       " u'archetyp',\n",
       " 'archvillain',\n",
       " u'area',\n",
       " 'arena',\n",
       " 'arf',\n",
       " u'arguabl',\n",
       " u'argument',\n",
       " u'aris',\n",
       " u'arm',\n",
       " u'armi',\n",
       " u'aros',\n",
       " 'around',\n",
       " u'arous',\n",
       " u'arrang',\n",
       " 'array',\n",
       " u'arriv',\n",
       " u'arrog',\n",
       " 'art',\n",
       " u'artist',\n",
       " u'artistri',\n",
       " 'asan',\n",
       " 'asap',\n",
       " u'asham',\n",
       " u'asid',\n",
       " 'ask',\n",
       " 'asleep',\n",
       " 'aspect',\n",
       " u'aspir',\n",
       " 'assault',\n",
       " u'assess',\n",
       " u'assid',\n",
       " u'assign',\n",
       " u'associ',\n",
       " u'assuag',\n",
       " u'assum',\n",
       " u'assumpt',\n",
       " u'assur',\n",
       " u'astonish',\n",
       " u'astonishingli',\n",
       " u'astound',\n",
       " u'astoundingli',\n",
       " u'astut',\n",
       " 'ate',\n",
       " u'athlet',\n",
       " u'atmospher',\n",
       " 'atrisk',\n",
       " u'attach',\n",
       " 'attack',\n",
       " 'attempt',\n",
       " u'attend',\n",
       " u'attent',\n",
       " u'attitud',\n",
       " 'attorney',\n",
       " u'attract',\n",
       " u'audibl',\n",
       " u'audienc',\n",
       " 'audio',\n",
       " 'audiobook',\n",
       " 'aunt',\n",
       " 'austen',\n",
       " 'australia',\n",
       " u'authent',\n",
       " 'author',\n",
       " u'authoress',\n",
       " u'authori',\n",
       " u'avail',\n",
       " u'avalanch',\n",
       " u'averag',\n",
       " 'avid',\n",
       " u'avoid',\n",
       " u'aw',\n",
       " u'await',\n",
       " u'awak',\n",
       " u'awar',\n",
       " 'away',\n",
       " u'awe',\n",
       " u'awesom',\n",
       " u'awhil',\n",
       " 'awkward',\n",
       " u'awkwardli',\n",
       " u'babi',\n",
       " 'back',\n",
       " u'backbit',\n",
       " 'backdoor',\n",
       " 'backdrop',\n",
       " u'backfir',\n",
       " u'background',\n",
       " u'backstab',\n",
       " u'backstori',\n",
       " u'backward',\n",
       " 'bad',\n",
       " u'badli',\n",
       " 'bag',\n",
       " u'balanc',\n",
       " u'ball',\n",
       " u'banal',\n",
       " 'band',\n",
       " 'barbara',\n",
       " 'bare',\n",
       " u'barri',\n",
       " u'barrymor',\n",
       " u'base',\n",
       " u'basebal',\n",
       " u'bash',\n",
       " u'basi',\n",
       " u'basic',\n",
       " 'basket',\n",
       " u'basketbal',\n",
       " 'bat',\n",
       " u'bate',\n",
       " 'bath',\n",
       " u'bathroom',\n",
       " 'bbc',\n",
       " 'bc',\n",
       " u'be',\n",
       " 'beach',\n",
       " 'bear',\n",
       " u'beast',\n",
       " u'beat',\n",
       " u'beater',\n",
       " u'beauti',\n",
       " u'becacaus',\n",
       " u'becam',\n",
       " u'becom',\n",
       " 'bed',\n",
       " 'bedroom',\n",
       " u'bedtim',\n",
       " 'began',\n",
       " 'beget',\n",
       " u'begin',\n",
       " u'beguil',\n",
       " u'behav',\n",
       " 'behavior',\n",
       " 'behaviour',\n",
       " 'behind',\n",
       " u'being',\n",
       " 'belief',\n",
       " u'believ',\n",
       " 'bellchapel',\n",
       " u'belli',\n",
       " u'belliger',\n",
       " u'belong',\n",
       " u'belov',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'beset',\n",
       " 'best',\n",
       " u'bestsel',\n",
       " u'besttak',\n",
       " u'betray',\n",
       " 'better',\n",
       " u'bevi',\n",
       " 'beyond',\n",
       " u'beyondthi',\n",
       " u'bias',\n",
       " u'bibl',\n",
       " u'bibliophil',\n",
       " u'bicker',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " u'bigotri',\n",
       " 'billion',\n",
       " u'billionair',\n",
       " u'binchi',\n",
       " u'bind',\n",
       " 'bing',\n",
       " 'bird',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " u'bite',\n",
       " 'bitter',\n",
       " u'bitterlki',\n",
       " 'black',\n",
       " u'blackandwhit',\n",
       " u'blade',\n",
       " 'blame',\n",
       " 'blanch',\n",
       " 'bland',\n",
       " 'blank',\n",
       " u'blatantli',\n",
       " 'bleak',\n",
       " 'bleaker',\n",
       " u'bleed',\n",
       " 'blend',\n",
       " u'bless',\n",
       " 'blind',\n",
       " u'blister',\n",
       " u'bloat',\n",
       " u'blockbust',\n",
       " 'blog',\n",
       " 'bloodbath',\n",
       " u'bloodi',\n",
       " u'bloodthirsti',\n",
       " 'blossom',\n",
       " 'blow',\n",
       " 'blue',\n",
       " 'blunt',\n",
       " u'blur',\n",
       " 'blurb',\n",
       " u'boar',\n",
       " 'board',\n",
       " u'bog',\n",
       " u'bogg',\n",
       " u'bold',\n",
       " u'boldli',\n",
       " u'bomb',\n",
       " u'bone',\n",
       " 'boo',\n",
       " u'book',\n",
       " 'booker',\n",
       " 'booki',\n",
       " 'bookjust',\n",
       " u'bookmark',\n",
       " 'booknot',\n",
       " u'booksbett',\n",
       " 'bookslet',\n",
       " 'bookso',\n",
       " u'bookstor',\n",
       " u'bookth',\n",
       " u'boom',\n",
       " 'boorish',\n",
       " u'border',\n",
       " u'bore',\n",
       " 'boredom',\n",
       " 'boreingfound',\n",
       " 'borrow',\n",
       " u'bother',\n",
       " 'bottom',\n",
       " u'bottomlin',\n",
       " 'bought',\n",
       " u'bounc',\n",
       " 'bow',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'brace',\n",
       " 'brain',\n",
       " 'branch',\n",
       " 'brandnew',\n",
       " 'brava',\n",
       " 'bravado',\n",
       " 'brave',\n",
       " 'bravo',\n",
       " 'breadth',\n",
       " u'break',\n",
       " 'breakaway',\n",
       " 'breaker',\n",
       " u'breast',\n",
       " u'breath',\n",
       " u'breathtak',\n",
       " 'breed',\n",
       " u'bridgewat',\n",
       " 'brief',\n",
       " u'briefli',\n",
       " 'brighter',\n",
       " 'brightest',\n",
       " 'brillant',\n",
       " u'brillianc',\n",
       " 'brilliant',\n",
       " 'brillianti',\n",
       " u'brilliantli',\n",
       " 'bring',\n",
       " u'brit',\n",
       " 'britain',\n",
       " 'british',\n",
       " 'britisk',\n",
       " 'britney',\n",
       " 'broad',\n",
       " 'broken',\n",
       " u'brooksid',\n",
       " u'broomstick',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brutal',\n",
       " u'bu',\n",
       " u'buck',\n",
       " u'bucket',\n",
       " u'bucol',\n",
       " 'budget',\n",
       " 'buffet',\n",
       " u'buffoon',\n",
       " u'build',\n",
       " 'built',\n",
       " 'builtin',\n",
       " u'bull',\n",
       " u'bulli',\n",
       " u'bum',\n",
       " 'bummer',\n",
       " 'bunch',\n",
       " 'burner',\n",
       " 'burst',\n",
       " u'busi',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'c',\n",
       " 'ca',\n",
       " u'calam',\n",
       " 'calendar',\n",
       " u'calib',\n",
       " u'call',\n",
       " 'came',\n",
       " 'camp',\n",
       " u'campaign',\n",
       " u'canari',\n",
       " u'candid',\n",
       " u'candl',\n",
       " 'canon',\n",
       " 'cant',\n",
       " 'cantwo',\n",
       " u'capabl',\n",
       " u'capac',\n",
       " u'capit',\n",
       " 'capitalist',\n",
       " u'capitil',\n",
       " u'captiv',\n",
       " u'captur',\n",
       " 'car',\n",
       " u'caract',\n",
       " 'cardboard',\n",
       " u'cardboardlik',\n",
       " 'care',\n",
       " 'career',\n",
       " u'caricatur',\n",
       " 'carol',\n",
       " u'carpentri',\n",
       " u'carri',\n",
       " 'cartoonish',\n",
       " 'case',\n",
       " u'cash',\n",
       " 'cast',\n",
       " u'castl',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'cataclysm',\n",
       " 'catalyst',\n",
       " u'catapult',\n",
       " u'catastroph',\n",
       " 'catch',\n",
       " 'catcher',\n",
       " u'categor',\n",
       " u'categori',\n",
       " 'caught',\n",
       " 'cauldron',\n",
       " u'caus',\n",
       " 'causal',\n",
       " 'caustic',\n",
       " 'cave',\n",
       " 'caveat',\n",
       " 'cd',\n",
       " u'celebr',\n",
       " 'cent',\n",
       " u'center',\n",
       " u'centr',\n",
       " 'central',\n",
       " u'centuri',\n",
       " 'certain',\n",
       " u'certainli',\n",
       " 'cesspool',\n",
       " 'chadha',\n",
       " 'chain',\n",
       " 'chairman',\n",
       " u'chalk',\n",
       " u'challeng',\n",
       " u'challengesstruggl',\n",
       " u'chanc',\n",
       " u'chang',\n",
       " u'chao',\n",
       " u'chapter',\n",
       " u'charact',\n",
       " u'character',\n",
       " 'characterdriven',\n",
       " u'characteris',\n",
       " u'characterist',\n",
       " 'charactersand',\n",
       " 'charactersplot',\n",
       " 'charactor',\n",
       " u'charcat',\n",
       " 'charcter',\n",
       " u'charg',\n",
       " u'charit',\n",
       " u'chariti',\n",
       " u'charli',\n",
       " u'charm',\n",
       " 'chart',\n",
       " 'chase',\n",
       " 'chatter',\n",
       " u'chatti',\n",
       " 'cheap',\n",
       " u'cheat',\n",
       " u'check',\n",
       " 'checklist',\n",
       " 'cheer',\n",
       " u'chew',\n",
       " 'chic',\n",
       " 'chief',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'childrensteen',\n",
       " 'childrenyoung',\n",
       " 'chill',\n",
       " 'chimera',\n",
       " 'chip',\n",
       " 'chock',\n",
       " u'choic',\n",
       " u'choos',\n",
       " 'chop',\n",
       " u'choppi',\n",
       " 'choral',\n",
       " 'chore',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " u'christi',\n",
       " u'christma',\n",
       " u'chronicl',\n",
       " u'chuckl',\n",
       " 'churn',\n",
       " u'cinemat',\n",
       " u'circl',\n",
       " u'circumst',\n",
       " u'citi',\n",
       " u'citizen',\n",
       " 'civil',\n",
       " u'claim',\n",
       " 'clan',\n",
       " 'claptrap',\n",
       " u'clarenc',\n",
       " u'clariti',\n",
       " u'class',\n",
       " u'classconscieni',\n",
       " u'classi',\n",
       " 'classic',\n",
       " u'classifi',\n",
       " 'classism',\n",
       " 'classroom',\n",
       " u'claustrophob',\n",
       " 'clean',\n",
       " 'clear',\n",
       " 'clearer',\n",
       " u'clearli',\n",
       " 'clever',\n",
       " u'clich',\n",
       " 'click',\n",
       " 'cliff',\n",
       " u'cliffhang',\n",
       " u'climact',\n",
       " 'climax',\n",
       " 'climb',\n",
       " 'cling',\n",
       " u'clinic',\n",
       " u'clip',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'closet',\n",
       " u'closur',\n",
       " 'cloud',\n",
       " u'cloudi',\n",
       " u'cloy',\n",
       " 'club',\n",
       " 'clubi',\n",
       " 'clue',\n",
       " u'clueless',\n",
       " u'clumsi',\n",
       " u'cluster',\n",
       " u'clutter',\n",
       " u'coars',\n",
       " 'coaster',\n",
       " u'cobbl',\n",
       " u'code',\n",
       " u'cohes',\n",
       " 'cold',\n",
       " u'collaps',\n",
       " u'colleagu',\n",
       " u'collect',\n",
       " u'colleg',\n",
       " u'collegeag',\n",
       " u'collis',\n",
       " u'collus',\n",
       " u'color',\n",
       " u'colorless',\n",
       " u'column',\n",
       " u'combat',\n",
       " u'combin',\n",
       " u'come',\n",
       " u'comedi',\n",
       " u'comeupp',\n",
       " u'comfort',\n",
       " u'comic',\n",
       " u'command',\n",
       " u'comment',\n",
       " u'commentari',\n",
       " u'commiser',\n",
       " u'commit',\n",
       " u'commodifi',\n",
       " 'common',\n",
       " u'commun',\n",
       " u'commut',\n",
       " u'compani',\n",
       " 'companion',\n",
       " u'compar',\n",
       " u'comparison',\n",
       " u'compass',\n",
       " u'compassion',\n",
       " u'compel',\n",
       " 'compendium',\n",
       " u'compens',\n",
       " u'compet',\n",
       " u'competit',\n",
       " u'compil',\n",
       " u'complac',\n",
       " 'complain',\n",
       " 'complaint',\n",
       " u'complet',\n",
       " 'completeley',\n",
       " 'complex',\n",
       " u'complic',\n",
       " 'comprehend',\n",
       " u'compuls',\n",
       " u'comput',\n",
       " 'conceal',\n",
       " u'conceiv',\n",
       " u'concentr',\n",
       " 'concept',\n",
       " u'concern',\n",
       " u'concis',\n",
       " u'conclud',\n",
       " u'conclus',\n",
       " u'concret',\n",
       " 'condemn',\n",
       " u'condit',\n",
       " u'confederaci',\n",
       " u'confess',\n",
       " u'confid',\n",
       " u'confin',\n",
       " u'confirm',\n",
       " 'conflict',\n",
       " 'confront',\n",
       " u'confus',\n",
       " u'confusingli',\n",
       " 'confusiong',\n",
       " u'congratul',\n",
       " u'conjur',\n",
       " 'connect',\n",
       " u'conscienc',\n",
       " u'consciou',\n",
       " u'consensu',\n",
       " u'consequ',\n",
       " u'conserv',\n",
       " u'consid',\n",
       " u'consider',\n",
       " u'consist',\n",
       " u'consolid',\n",
       " 'constant',\n",
       " u'constantli',\n",
       " u'construct',\n",
       " u'consum',\n",
       " 'contain',\n",
       " u'contempl',\n",
       " u'contemporari',\n",
       " u'contemptu',\n",
       " 'content',\n",
       " 'context',\n",
       " u'contin',\n",
       " u'continu',\n",
       " u'contrari',\n",
       " 'contrast',\n",
       " u'contribut',\n",
       " u'contriv',\n",
       " 'control',\n",
       " u'controsept',\n",
       " u'convent',\n",
       " u'converg',\n",
       " u'convers',\n",
       " u'convey',\n",
       " u'convinc',\n",
       " u'convolut',\n",
       " 'cool',\n",
       " 'cope',\n",
       " u'copi',\n",
       " 'copperfield',\n",
       " 'core',\n",
       " 'cormoran',\n",
       " u'corneliu',\n",
       " u'coron',\n",
       " 'correct',\n",
       " u'correctli',\n",
       " u'corrupt',\n",
       " 'cost',\n",
       " 'costco',\n",
       " 'could',\n",
       " 'couldnt',\n",
       " 'council',\n",
       " 'councillor',\n",
       " 'councilman',\n",
       " u'counsellor',\n",
       " 'count',\n",
       " u'counter',\n",
       " u'counterbalanc',\n",
       " u'counterpart',\n",
       " u'counterpoint',\n",
       " u'countless',\n",
       " u'countri',\n",
       " u'countrysid',\n",
       " u'coupl',\n",
       " u'courag',\n",
       " u'cours',\n",
       " u'cover',\n",
       " u'cowardic',\n",
       " u'cozi',\n",
       " 'craft',\n",
       " u'cram',\n",
       " 'crap',\n",
       " u'crappi',\n",
       " 'crappola',\n",
       " u'crash',\n",
       " u'crass',\n",
       " u'crave',\n",
       " u'crazi',\n",
       " u'creat',\n",
       " 'creation',\n",
       " u'creativ',\n",
       " u'creatur',\n",
       " u'credibl',\n",
       " u'creep',\n",
       " u'creepi',\n",
       " 'crescendo',\n",
       " u'cri',\n",
       " 'crime',\n",
       " u'crimin',\n",
       " u'cring',\n",
       " u'crippl',\n",
       " 'criteria',\n",
       " u'critic',\n",
       " u'cross',\n",
       " 'crowd',\n",
       " 'crude',\n",
       " 'cruel',\n",
       " 'cruelest',\n",
       " u'cruelti',\n",
       " u'cruis',\n",
       " u'crumbl',\n",
       " u'crummi',\n",
       " 'cs',\n",
       " u'cubbi',\n",
       " 'cuckoo',\n",
       " u'culmin',\n",
       " u'cultur',\n",
       " u'cumbersom',\n",
       " 'cup',\n",
       " u'cure',\n",
       " u'curios',\n",
       " u'curiou',\n",
       " 'current',\n",
       " u'curs',\n",
       " 'curt',\n",
       " u'curtail',\n",
       " 'curtain',\n",
       " u'cuss',\n",
       " u'cussi',\n",
       " 'cut',\n",
       " u'cutout',\n",
       " 'cword',\n",
       " u'cycl',\n",
       " u'cynic',\n",
       " 'dahl',\n",
       " u'daili',\n",
       " u'dalla',\n",
       " u'damag',\n",
       " 'dan',\n",
       " u'dandi',\n",
       " 'danger',\n",
       " u'dangl',\n",
       " u'daniel',\n",
       " 'dare',\n",
       " 'dark',\n",
       " 'darker',\n",
       " 'darkest',\n",
       " u'darkli',\n",
       " u'darn',\n",
       " 'dash',\n",
       " u'dataentri',\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4621"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed feature matrix `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "train_X = vectorizer.transform(train_X)\n",
    "test_X = vectorizer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ..., \n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # TODO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_model.LogisticRegression(random_state = 0).fit(train_X, train_c)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86254295532646053"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_X, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = tree.DecisionTreeClassifier(max_depth = 10, min_samples_leaf = 5, random_state = 0,\\\n",
    "                                   ).fit(train_X, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.57731958762886593"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_X, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72852233676975942"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100, max_depth = 10, min_samples_leaf = 5, random_state = 0,\\\n",
    "                                   ).fit(train_X, train_c)\n",
    "model.score(train_X, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.53608247422680411"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_X, test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
